{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cusom datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part will focus on creating a dataset and then predicting on it\n",
    "The dataset chosen is a subset of the Food101 dataset and contains 3 different classes: \n",
    "* Pizza\n",
    "* Steak\n",
    "* Sushi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch as pt\n",
    "from torch import nn\n",
    "\n",
    "print(f\"Torch version: {pt.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup device agnostic code\n",
    "device = 'cuda' if pt.cuda.is_available() else 'cpu'\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading a custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import importLib\n",
    "from sys import path\n",
    "import zipfile\n",
    "\n",
    "\n",
    "# Create directory\n",
    "data_path = Path(f\"{path[0]}/data\")\n",
    "image_path = data_path / 'pizza_steak_sushi'\n",
    "if image_path.exists():\n",
    "    print('Already exists')\n",
    "else:\n",
    "    image_path.mkdir(parents=True)\n",
    "\n",
    "\n",
    "# Download pizza, steak and sushi data\n",
    "# open skapar en zip fil som sedan fylls genom request\n",
    "importLib.import_from_github('https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip',directory=data_path)\n",
    "with zipfile.ZipFile(data_path/'pizza_steak_sushi.zip', 'r') as zip_ref:\n",
    "    print('Unzipping pizza, steak and sushi data')\n",
    "    zip_ref.extractall(image_path)\n",
    "Path.unlink(data_path/'pizza_steak_sushi.zip')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Become one with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def walk_through_dir(dir_path):\n",
    "    \"\"\"Walks through dir_path and returns its contents\"\"\"\n",
    "    for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "        print(f\"There are {len(dirnames)} directories and {len(filenames)} images in {dirpath}\")\n",
    "walk_through_dir(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training and testing paths\n",
    "train_dir = image_path / 'train'\n",
    "test_dir = image_path / 'test'\n",
    "\n",
    "train_dir, test_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write some code to:\n",
    "1. Get all the image paths (pathlib)\n",
    "2. Pick a random path\n",
    "3. Get the image class name, by looking at the pathlib.Path.parent.stem\n",
    "4. Since we are working with images, we will open it with PIL\n",
    "5. Show image and print metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import random\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "# Set seed\n",
    "seed = None\n",
    "random.seed(None)\n",
    "\n",
    "# 1. Get all image paths\n",
    "image_path_list = (list(image_path.glob('*/*/*.jpg'))) # glob together every image with a certain pattern\n",
    "print(f'This globs together all the {len(image_path_list)} images inside pizza_steak_sushi')\n",
    "random_image_path = random.choice(image_path_list)\n",
    "print(\"Chosen random image: \"+random_image_path.name)\n",
    "print('Class is a: '+random_image_path.parent.stem)\n",
    "img = Image.open(random_image_path)\n",
    "print(f\"Height: {img.height}\")\n",
    "print(f\"Width: {img.width}\")\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = transforms.Compose([transforms.PILToTensor()])(img)\n",
    "print(tensor.shape)\n",
    "tensor = tensor.permute(2, 1,0)\n",
    "# plot image\n",
    "plt.title(f'Random image of {random_image_path.parent.stem}')\n",
    "plt.imshow(tensor)\n",
    "plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can use our data:\n",
    "1. Turn target data to tensors, in this case: Pictures -> tensors\n",
    "2. Turn it to a `torch.utils.data.Dataset` and subsequently (afterwards) into a `torch.utils.data.Dataloader`, (Batched dataset)\n",
    "\n",
    "Information and help regarding transforms: https://pytorch.org/vision/stable/transforms.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as pt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a transform for image\n",
    "# transforms.Compose is similar to nn.Sequential where it can hold many different transforms\n",
    "data_transform = transforms.Compose([\n",
    "    # Resize our images to a set size to ensure compability with our modules shape handeling\n",
    "    transforms.Resize(size=(64, 64)),\n",
    "    # Flip the image half of the time it goes through this pipeline\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    # Turn the image into a torch.Tensor\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('After transformation')\n",
    "plt.imshow(data_transform(img).permute(1,2,0))\n",
    "plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transformed_images(image_paths:str, transform:transforms, n:int=3, seed:int=None):\n",
    "    \"\"\"Plot difference between transformed images and normal\n",
    "    \n",
    "    args:\n",
    "        image_paths (Sequence[Path()]): List of image file paths.\n",
    "        transform (torchvision.transforms): Image transformation object.\n",
    "        num_images (int, optional): Number of images to display. Default is 3.\n",
    "        seed (int, optional): Random seed for image selection. Default is None.\"\"\"\n",
    "    from random import sample, seed as random_seed\n",
    "    random_seed(seed)\n",
    "    image_paths = sample(image_paths,k=n)\n",
    "    fig, ax = plt.subplots(nrows=len(image_paths),ncols=2)\n",
    "    for i,img_path in enumerate(image_paths):\n",
    "        with Image.open(img_path) as f:\n",
    "            ax[i,0].imshow(f)\n",
    "            ax[i,1].imshow(transform(f).permute(1,2,0))\n",
    "            ax[i,0].axis(False)\n",
    "            ax[i,0].set_title(f\"Size: {f.size}\")\n",
    "            ax[i,1].axis(False)\n",
    "            ax[i,1].set_title(f'Size: ({str(transform(f).permute(1,2,0).size())[12:-2]})')\n",
    "\n",
    "    plt.tight_layout(w_pad=-10)\n",
    "\n",
    "    plt.subplots_adjust(top=0.8)\n",
    "    plt.suptitle('Images\\nOriginal    Transformed', fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_transformed_images(image_path_list, data_transform,3,seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading all of our images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 1: Loading image data usin `ImageFolder`: https://pytorch.org/vision/stable/generated/torchvision.datasets.ImageFolder.html\n",
    "\n",
    "Option 2: Do it by yourself\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "# the ImageFolder class makes a division automaticly without having to hardcode it, because we have our data already structured in the pytorch style with first the dataset then train and test dir with pictures in them \n",
    "train_data = datasets.ImageFolder(root=train_dir, \n",
    "                                  transform=data_transform, # a transform for the data\n",
    "                                  target_transform=None, # a transform for the targets/labels\n",
    "                                  )\n",
    "test_data = datasets.ImageFolder(root=test_dir, \n",
    "                                  transform=data_transform, # a transform for the data\n",
    "                                  target_transform=None, # a transform for the targets/labels\n",
    "                                  )\n",
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "img = random.choice(test_data)\n",
    "plt.imshow(img[0].permute(1,2,0))\n",
    "plt.title(test_data.classes[img[1]])\n",
    "plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "print(f\"Cpu cores available: {os.cpu_count()}\")\n",
    "\n",
    "\n",
    "\n",
    "# Ett alternativ för drop last: \n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS) # Basically how many cpu cores are used to load the data, sätts ofta till os.cpu_count() alltså alla som ges\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS)\n",
    " # Basically how many cpu cores are used to load the data, sätts ofta till os.cpu_count() alltså alla som ges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataloader), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = next(iter(train_dataloader))\n",
    "print(img.shape, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By our own"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We want to be able to load images from file\n",
    "2. We want to be able to get classes from Dataset\n",
    "3. We want to get classes as dict as well\n",
    "\n",
    "All custom datasets in python often subclass - https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import pathlib\n",
    "import torch as pt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from typing import Tuple, Dict, List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a helper function to get class names and one for class names as dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want our function to\n",
    "1. Get the class names using `os.scandir()` to traverse a target directory\n",
    "2. Raise an error if the class names are not found\n",
    "3. Turn the class names into a dict and a list and return them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup path for target directory\n",
    "target_directory = train_dir\n",
    "print(f\"Target dir: {target_directory}\")\n",
    "\n",
    "# Get the class names from the target directory\n",
    "class_names_found = sorted([entry.name for entry in list(os.scandir(target_directory))])\n",
    "dict([(class_name, i) for i, class_name in enumerate(class_names_found)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(directory:str) -> List[str]:\n",
    "    classes = sorted([entry.name for entry in list(os.scandir(directory))])\n",
    "    classes_to_idx =  {class_name:i for i, class_name in enumerate(class_names_found)}\n",
    "    return classes, classes_to_idx\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a custom `dataset` to replicate `ImageFolder`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Subclass `torch.utils.data.Dataset`\n",
    "2. Initialize our subclass with target dir as well as transform with transforms\n",
    "3. Create several attributes:\n",
    "    * paths - the paths of our images\n",
    "    * transform - the transform we would like to use\n",
    "    * classes - a list of the target classes\n",
    "    * classes_to_idx - a dict of the target classes mapped to integer labels\n",
    "4. Create a function to load_images() to open an image\n",
    "5. Overwrite the __len__() method to return the length of the dataset\n",
    "6. Overwrite the __getitem__() method to return a given sample when passed an index\n",
    "\n",
    "\n",
    "Pros:\n",
    "* Customizability\n",
    "\n",
    "Con:\n",
    "* Prone to errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a cutom dataset class\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class ImageFolderCustom(Dataset):\n",
    "    def __get_classes(self):\n",
    "        classes = sorted([entry.name for entry in list(os.scandir(self.targ_dir))])\n",
    "        classes_to_idx = {class_name:i for i, class_name in enumerate(classes)}\n",
    "        return classes, classes_to_idx\n",
    "\n",
    "    def __get_class(self, directory:str) -> str:\n",
    "        return self.classes_to_idx[Path(directory).parent.name]\n",
    "\n",
    "\n",
    "    def __init__(self, targ_dir:str, transform=None):\n",
    "        super().__init__()\n",
    "        self.targ_dir = targ_dir\n",
    "\n",
    "        # Create class attributes\n",
    "\n",
    "        # Get all of the image paths\n",
    "        # alltså tar denna in exempelvis test foldern som targ_dir och tar alla värden från foldrarna i den som slutar på jpg\n",
    "        self.paths = list(pathlib.Path(targ_dir).glob(\"*/*.jpg\")) \n",
    "        \n",
    "        # Setup transforms\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Create classes and class_to_idx attributes\n",
    "        self.classes, self.classes_to_idx = self.__get_classes()\n",
    "\n",
    "        # Create targets\n",
    "        self.targets = [self.__get_class(el) for el in self.paths]\n",
    "    def load_image(self, index:int) -> Image.Image: \n",
    "        \"\"\"Opens an image via path using index and returns it\"\"\"\n",
    "        return Image.open(self.paths[index])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Returns the total number of samples\"\"\"\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, index) -> Tuple[pt.Tensor, int]:\n",
    "        img = self.load_image(index)\n",
    "        class_name = self.paths[index].parent.name # gets the folder and then takes the parents name, i.e pizza/steak/sushi\n",
    "        class_idx = self.classes_to_idx[class_name] # Uses the dictionary classes_to_idx to get the index of the class\n",
    "\n",
    "        if self.transform: # Om man har specifierat self.transform så den inte är None\n",
    "            return self.transform(img), class_idx\n",
    "        return img, class_idx\n",
    "\n",
    "\n",
    "train_data_custom = ImageFolderCustom(\n",
    "    targ_dir=train_dir,\n",
    "    transform= None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test  the dataset with Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(64,64)),\n",
    "    transforms.RandomHorizontalFlip(0.5), # \"artificially changing our data to broaden the dataset\"\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(64,64)), # Här skippar vi data augmentation, alltså förändring av data för att bredda utbudet av data för bättre träning, då detta ändå bara är till testande\n",
    "    transforms.ToTensor() \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_custom = ImageFolderCustom(\n",
    "    targ_dir=train_dir,\n",
    "    transform= train_transform\n",
    ")\n",
    "test_data_custom = ImageFolderCustom(\n",
    "    targ_dir=train_dir,\n",
    "    transform= test_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data_custom, test_data_custom)\n",
    "\n",
    "print(\"\\n\", len(train_data), len(train_data_custom))\n",
    "\n",
    "print(train_data.classes, train_data_custom.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test by visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Take in a `dataset` + other parameters for visualization\n",
    "2. Cap number of images to see at ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_funcs import view\n",
    "view.rand_images(test_data_custom,seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turn custom loaded images into DataLoader's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cpu cores available: 4\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from numpy import round\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "#NUM_WORKERS = 2 # How many cpu cores we will use\n",
    "print(f\"Cpu cores available: {os.cpu_count()}\") # optionally we can make num_workers to this, or a part of this, by code examplewise\n",
    "NUM_WORKERS = int(round(os.cpu_count()*(3/4))) # Här kan man välja hur många cores som används\n",
    "\n",
    "\n",
    "print(NUM_WORKERS)\n",
    "train_dataloader_custom = DataLoader(\n",
    "    dataset=train_data_custom,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=True)\n",
    "\n",
    "train_dataloader_custom = DataLoader(\n",
    "    dataset=test_data_custom,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation (just a snippet, but a general one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`A technic used to increase the amount of data by adding slightly modified copies of already existing data or newly created synthetic data from existing model`\n",
    "\n",
    "Examples of ways to do so:\n",
    "* Rotate\n",
    "* Shift, move the picture a bit right, left, up, down\n",
    "* Zoom\n",
    "* Twist, twist the corners of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
