{"cells":[{"cell_type":"markdown","metadata":{"id":"WHUYnvoRT_Os"},"source":["### Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5074,"status":"ok","timestamp":1692627375641,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"p1WWYmzXT_Ou","outputId":"e8407948-f493-43dd-beb9-9179d93e25d8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Torch version: 2.0.1+cu118\n","device: cpu\n"]}],"source":["# Imports\n","import torch as pt\n","from torch import nn\n","\n","print(f\"Torch version: {pt.__version__}\")\n","\n","# if pt.cuda.is_available():\n","#     device = 'cuda'\n","# if pt.backends.mps.is_available():\n","#     device = 'mps'\n","# else:\n","#     device= 'cpu'\n","device = 'cpu'\n","print(f'device: {device}')"]},{"cell_type":"markdown","metadata":{"id":"Mn8lma6QT_Ov"},"source":["### Downloading a custom dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":477},"executionInfo":{"elapsed":306,"status":"error","timestamp":1692627420987,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"0FXgAgVmT_Ov","outputId":"de6efe5a-cea4-4e57-b13e-067e381cb556"},"outputs":[{"name":"stdout","output_type":"stream","text":["Already exists\n","/Users/gustavgamstedt/Desktop/github to hemma/PyTorch/04/video/data/pizza_steak_sushi.zip doesn't exist, download\n","Unzipping pizza, steak and sushi data\n"]}],"source":["from pathlib import Path\n","import importLib\n","from sys import path\n","import zipfile\n","\n","\n","# Create directory\n","data_path = Path(f\"{path[0]}/data\")\n","image_path = data_path / 'pizza_steak_sushi'\n","if image_path.exists():\n","    print('Already exists')\n","else:\n","    image_path.mkdir(parents=True)\n","\n","\n","# Download pizza, steak and sushi data\n","# open skapar en zip fil som sedan fylls genom request\n","importLib.import_from_github('https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip',directory=data_path)\n","with zipfile.ZipFile(data_path/'pizza_steak_sushi.zip', 'r') as zip_ref:\n","    print('Unzipping pizza, steak and sushi data')\n","    zip_ref.extractall(image_path)\n","Path.unlink(data_path/'pizza_steak_sushi.zip')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":325,"status":"ok","timestamp":1692627446762,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"BCf41f1hT_Ov","outputId":"007cae5e-03fa-4f6d-c3f6-9cf01f5224e2"},"outputs":[{"data":{"text/plain":["(PosixPath('/content/data/pizza_steak_sushi/train'),\n"," PosixPath('/content/data/pizza_steak_sushi/test'))"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Setup training and testing paths\n","train_dir = image_path / 'train'\n","test_dir = image_path / 'test'\n","\n","train_dir, test_dir"]},{"cell_type":"markdown","metadata":{"id":"EMvNq3QJT_Ow"},"source":["### Create dataset and dataloaders"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VLcjS6k8T_Ow"},"outputs":[],"source":["from torchvision import transforms\n","simple_transform = transforms.Compose([\n","    transforms.Resize((64,64)),\n","    transforms.ToTensor(),\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":425},"executionInfo":{"elapsed":390,"status":"error","timestamp":1692627447873,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"-79l2SV0T_Ow","outputId":"05b9135d-6d37-4951-a550-1decb6d86efc"},"outputs":[{"ename":"FileNotFoundError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-55544654c930>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msimple_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msimple_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mis_valid_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     ):\n\u001b[0;32m--> 309\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    142\u001b[0m     ) -> None:\n\u001b[1;32m    143\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \"\"\"\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \"\"\"\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data/pizza_steak_sushi/train'"]}],"source":["from torchvision import datasets\n","\n","train_dataset = datasets.ImageFolder(root = train_dir, transform=simple_transform)\n","test_dataset = datasets.ImageFolder(root = test_dir, transform=simple_transform)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N5tb2d8sT_Ow"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","import os\n","BATCH_SIZE = 32\n","NUM_WORKERS = round(os.cpu_count()*(3/4))\n","train_dataloader = DataLoader(\n","    dataset=train_dataset,\n","    batch_size=BATCH_SIZE,\n","    num_workers=NUM_WORKERS,\n","    shuffle=True\n",")\n","\n","test_dataloader = DataLoader(\n","    dataset=test_dataset,\n","    batch_size=BATCH_SIZE,\n","    num_workers=NUM_WORKERS,\n","    shuffle=False\n",")"]},{"cell_type":"markdown","metadata":{"id":"JNO15QLMT_Ox"},"source":["### Create a model without Augmention"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pzivTyy5T_Ox"},"outputs":[],"source":["from torch import nn\n","\n","class TinyVGG(nn.Module):\n","    def __init__(self, input_features:int,output_features:int, hidden_units:int=10):\n","        super().__init__()\n","        self.conv_block_1 = nn.Sequential(\n","            nn.Conv2d(input_features, hidden_units,\n","                      kernel_size=3, stride=1, padding=0),\n","            nn.ReLU(),\n","\n","\n","            nn.Conv2d(hidden_units, hidden_units,\n","                      kernel_size=3, stride=1, padding=0),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","\n","        self.conv_block_2 = nn.Sequential(\n","            nn.Conv2d(hidden_units, hidden_units,\n","                      kernel_size=3, stride=1, padding=0),\n","            nn.ReLU(),\n","\n","\n","            nn.Conv2d(hidden_units, hidden_units,\n","                      kernel_size=3, stride=1, padding=0),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","\n","        self.classifier = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(hidden_units*13*13, output_features)\n","        )\n","    def forward(self, X:pt.Tensor) -> pt.Tensor:\n","        X_change = self.conv_block_1(X)\n","        X_change = self.conv_block_2(X_change)\n","        # print(X_change.shape)\n","        X_change = self.classifier(X_change)\n","        return X_change"]},{"cell_type":"markdown","metadata":{"id":"QOlWiDd-T_Ox"},"source":["#### Testing model with random data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PfbemaIaT_Ox"},"outputs":[],"source":["pt.manual_seed(42)\n","model0 = TinyVGG(input_features=3, output_features=len(train_dataset.classes), hidden_units=10).to(device)\n","model0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QbT6aSU-T_Ox"},"outputs":[],"source":["imgs, labels = next(iter(train_dataloader))\n","print(imgs.shape, len(labels))\n","# model0(imgs[0].unsqueeze(0))\n","model0(imgs.to(device))"]},{"cell_type":"markdown","metadata":{"id":"i4njzx4qT_Oy"},"source":["### Summarize a model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JNNH266mT_Oy"},"outputs":[],"source":["try:\n","    import torchinfo\n","except ModuleNotFoundError:\n","    print('Module not found, installing module')\n","    !pip3 install torchinfo\n","    import torchinfo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N5MMfnqvT_Oy"},"outputs":[],"source":["torchinfo.summary(model0, input_size=[32,3,64,64],device=device)"]},{"cell_type":"markdown","metadata":{"id":"l0qsPkCIT_Oy"},"source":["### Create train and test loop functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pVZTGZQ0T_Oy"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","def train_step(model: pt.nn.Module,\n","               dataloader:DataLoader,\n","               loss_fn: pt.nn.Module,\n","               optimizer:pt.optim.Optimizer,\n","               device:pt.device,\n","               show:bool=False):\n","    \"\"\"Performs a training step with model trying to learn on data_loader\n","\n","    args:\n","        model: the model which will be trained on\n","        dataloader: A generator like loader for the data\n","        optimizer: Optimizer which optimizes the code through gradient descend\n","        loss_fn: function which calculates how far from the right answer each of the predictions were\n","        accuracy_fn: function which calculates how meny predictions were right\n","        device: chosen device for the neural network to run on (cpu/gpu/tpu)\n","        show: if true display the loss and acc in console\n","\n","    returns:\n","        (loss, accuracy)\"\"\"\n","    # Put model in training mode\n","    model.train()\n","\n","    # Setup train loss and train accuracy values\n","    train_loss, train_acc = 0,0\n","\n","    # Loop through data loader batches\n","    for X,y in dataloader:\n","        # Send data to target device\n","        X,y = X.to(device), y.to(device)\n","\n","        y_logits = model(X)\n","\n","        loss = loss_fn(y_logits, y)\n","        train_loss+=loss.item()\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        y_preds = pt.argmax(pt.softmax(y_logits, dim=1), dim=1) # Softmax is actually unnecessary, but can be useful for visualization and also to give completeness\n","        train_acc += (y_preds == y).sum().item()/len(y_preds)\n","    train_loss /= len(dataloader)\n","    train_acc  /= len(dataloader)\n","\n","    if show:\n","        print(f'Train loss: {train_loss} | Train acc: {train_acc}')\n","    return train_loss, train_acc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YIncxOAQT_Oy"},"outputs":[],"source":["def test_step(model: pt.nn.Module,\n","              dataloader:DataLoader,\n","              loss_fn: pt.nn.Module,\n","              device:pt.device,\n","              show:bool=False):\n","    \"\"\"Performs a testing loop step on model going over data_loader.\n","\n","    args:\n","        model: the model which will be trained on\n","        dataloader: A generator like loader for the data\n","        loss_fn: function which calculates how far from the right answer each of the predictions were\n","        accuracy_fn: function which calculates how meny predictions were right\n","        device: chosen device for the neural network to run on (cpu/gpu/tpu)\n","        show: if true display the loss and acc in console\n","\n","    returns:\n","        (loss, accuracy)\"\"\"\n","    test_acc, test_loss = 0,0\n","\n","    model.eval()\n","    with pt.inference_mode():\n","        for X,y in dataloader:\n","            X,y = X.to(device), y.to(device)\n","            y_logits = model(X)\n","            loss = loss_fn(y_logits, y)\n","            test_loss+=loss.item()\n","\n","            y_preds = pt.argmax(pt.softmax(y_logits, dim=1), dim=1)\n","            test_acc += (y_preds== y).sum().item()/len(y_preds)\n","    test_loss /= len(dataloader)\n","    test_acc  /= len(dataloader)\n","\n","    print(f'Test loss: {test_loss} | Test acc: {test_acc}') if show else None\n","    return test_loss, test_acc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7DoczMZZT_Oz"},"outputs":[],"source":["\n","from tqdm.notebook import tqdm\n","def train(epochs:int, model:pt.nn.Module, train_dataloader:DataLoader, test_dataloader:DataLoader, loss_fn, optimizer:pt.optim.Optimizer, device:pt.device,show:bool):\n","    \"\"\"Trains the model\"\"\"\n","    # Create an empty dictionary to hold results in\n","    results = {\n","        \"train_loss\":[],\n","        \"train_acc\":[],\n","        \"test_loss\":[],\n","        \"test_acc\":[]\n","        }\n","\n","    for epoch in tqdm(range(epochs)):\n","        print(f'Epoch: {epoch}') if show else None\n","        train_loss, train_acc = train_step(\n","            model=model,\n","            dataloader=train_dataloader,\n","            loss_fn=loss_fn,\n","            optimizer=optimizer,\n","            device=device,\n","            show=show)\n","\n","        test_loss, test_acc = test_step(\n","            model=model,\n","            dataloader= test_dataloader,\n","            loss_fn= loss_fn,\n","            device= device,\n","            show=show\n","            )\n","\n","        # Append our values to results\n","        results[\"train_loss\"].append(train_loss); results[\"train_acc\"].append(train_acc)\n","        results[\"test_loss\"].append(test_loss); results[\"test_acc\"].append(test_acc)\n","    return results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Iu52C_y7T_Oz"},"outputs":[],"source":["pt.manual_seed(42)\n","pt.cuda.manual_seed(42)\n","\n","# Set number of epochs\n","NUM_EPOCHS = 5\n","\n","# Recreate an instance of TinyVGG\n","model_0 = TinyVGG(3, len(train_dataset.classes), 10).to(device)\n","\n","loss_fn = nn.CrossEntropyLoss()\n","\n","optimizer = pt.optim.Adam(params=model_0.parameters(), lr=0.001)\n","\n","from ml_funcs import Timer\n","timer = Timer()\n","\n","# Train model_0\n","model_0_results = train(\n","    epochs=5,\n","    model=model_0,\n","    train_dataloader=train_dataloader,\n","    test_dataloader=test_dataloader,\n","    loss_fn=loss_fn,\n","    optimizer=optimizer,\n","    device=device,\n","    show=True)\n","timer.show_as_print()\n"]},{"cell_type":"markdown","metadata":{"id":"OsYD7U3YT_Oz"},"source":["### Save and load model + evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D2q1pasAT_Oz"},"outputs":[],"source":["from sys import path\n","model_path = f'{path[0]}/models'\n","from ml_funcs import save_load, Model_operations\n","\n","# save_load.save_state_dict(model_0, 'ModelWithoutAugmentation0', model_path)\n","try:\n","  loaded_model = save_load.load_state_dict(TinyVGG(3,len(train_dataset.classes), 10), 'ModelWithoutAugmentation0', model_path)\n","except FileNotFoundError:\n","  print('File not found')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0sfKddy3T_Oz"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","def plot_loss_curves(results: dict[str, list[float]]):\n","    \"\"\"Plots training curves of a results dictionary\"\"\"\n","    # Get the loss values of the results dictionary\n","\n","    # train results\n","    train_loss = results['train_loss']\n","    train_acc = results['train_acc']\n","\n","    # test results\n","    test_loss = results['test_loss']\n","    test_acc = results['test_acc']\n","\n","    # epochs\n","    epochs = range(len(results['train_loss']))\n","\n","    # Setup a plot\n","    plt.subplot(1,2,1)\n","    plt.plot(epochs, train_loss, label='train loss', color='red')\n","    plt.plot(epochs, test_loss, label='test loss', color='green')\n","    plt.title('Loss')\n","    plt.xlabel('Epochs')\n","    plt.legend()\n","\n","\n","    plt.subplot(1,2,2)\n","    plt.plot(epochs, train_acc, label='train accuracy',color='orange')\n","    plt.plot(epochs, test_acc, label='train accuracy', color='blue')\n","    plt.title('Accuracy')\n","    plt.xlabel('Epochs')\n","    plt.legend()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s6M68oJQT_Oz"},"outputs":[],"source":["plot_loss_curves(model_0_results)"]},{"cell_type":"markdown","metadata":{"id":"KzRce1X9T_Oz"},"source":["### Augmented model"]},{"cell_type":"markdown","metadata":{"id":"4NJWYY8mT_O0"},"source":["#### What does an ideal loss curve look line and how do you make your loss curve look ideal?\n","\n","https://developers.google.com/machine-learning/testing-debugging/metrics/interpretic\n","\n","How to see if your model is overfitting or underfitting:\n","\n","**Underfitting:**\n","* The models loss is high and reducing itself slowly\n","\n","**Overfitting:**\n","* Train loss is alot higher than test loss\n"]},{"cell_type":"markdown","metadata":{"id":"kTnaLHxyT_O0"},"source":["Now let's try another modelling experiment this time using the same model as before but with some data augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UscSQFNsT_O0"},"outputs":[],"source":["# Create training transform with TrivialAugment\n","from torchvision import transforms\n","train_transform_trivial = transforms.Compose([\n","    transforms.Resize((64,64)),\n","    transforms.TrivialAugmentWide(num_magnitude_bins=31), # between 0-31 in transformation\n","    transforms.ToTensor()\n","])\n","\n","test_transforms_simple = transforms.Compose([\n","    transforms.Resize((64,64))\n","])"]},{"cell_type":"markdown","metadata":{"id":"3xhGAyhaT_O0"},"source":["#### Create train and test Dataset+DataLoaders with data augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uIhlFlLcT_O0"},"outputs":[],"source":["from torchvision import datasets\n","from torch.utils.data import DataLoader\n","\n","BATCH_SIZE = 32\n","NUM_WORKERS = round(os.cpu_count()*(3/4))\n","pt.manual_seed(42)\n","\n","# Datasets\n","aug_train_data = datasets.ImageFolder(train_dir, train_transform_trivial)\n","aug_test_data = datasets.ImageFolder(test_dir, train_transform_trivial)\n","\n","# DataLoaders\n","aug_train_dataloader = DataLoader(dataset=aug_train_data, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True)\n","aug_test_dataloader = DataLoader(dataset=aug_test_data, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"OObNORChT_O0"},"source":["#### Create model 1 with data augmenatation, thus change the data, but not really the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WZ8zXkOPT_O0"},"outputs":[],"source":["#### Creat model 1 with data augmentation\n","pt.manual_seed(42)\n","model_1 = TinyVGG(3, len(aug_test_data.classes), 10).to(device)"]},{"cell_type":"markdown","metadata":{"id":"-mbZ5nX0T_O0"},"source":["#### Create the training loop using train() function"]},{"cell_type":"markdown","metadata":{"id":"B7qeh3iuT_O0"},"source":["As we can see our results point out that data augmentation isn't really needed, because our model performs better without data augmentation\n","\n","This can be seen on the loss curvature of model_0 which had a good negative mean gradient (pointed downwards quite much)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ff24itKLT_O0"},"outputs":[],"source":["from torch import nn\n","import torch as pt\n","from helper_functions import set_seeds\n","from ml_funcs import Timer, Model_operations\n","set_seeds(42)\n","NUM_EPOCHS = 5\n","\n","# Loss func\n","aug_loss_fn = nn.CrossEntropyLoss()\n","\n","# Optimizer\n","aug_optimizer = pt.optim.Adam(params=model_1.parameters(), lr=0.001)\n","\n","timer = Timer()\n","\n","# Train model 1\n","model_1_results = train(\n","    epochs=NUM_EPOCHS,\n","    model=model_1,\n","    train_dataloader=aug_train_dataloader,\n","    test_dataloader=aug_test_dataloader,\n","    loss_fn=aug_loss_fn,\n","    optimizer=aug_optimizer,\n","    device=device,\n","    show=True)\n","\n","timer.show_as_print()\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"BsWTkR5AT_O1"},"source":["Loss going up indicates something is going bad, to get a better view try with more epochs\n","\n","It looks as our model is both overfitting and underfitting as well, because of how the test_loss is quite a bit higher then our train loss and both are high values far from 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9W_viOLQT_O1"},"outputs":[],"source":["plot_loss_curves(model_1_results)"]},{"cell_type":"markdown","metadata":{"id":"vw7c4NLQVB6Q"},"source":["### 10. Compare model results\n","After evaluating our modelling expoeriments on their own, its time to compare them to each other\n","\n","There are a few different ways to do this:\n","1. Hard code it yourself\n","2. Pytorch + Tensorboard: https://pytorch.org/docs/stable/tensorboard.html\n","3. Weights & Biases: https://wandb.ai/site/experiment-tracking\n","4. MlFlow: https://mlflow.org/\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vL3ZG633cgts"},"outputs":[],"source":["# Import wandb or Weights and Biases\n","try:\n","    import wandb\n","except ModuleNotFoundError:\n","    print('Module not found, installing module')\n","    !pip3 install wandb\n","    import wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lkObHmkNcgts"},"outputs":[],"source":["'Log into the website'\n","wandb.login()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EkMvb-DCcgtt"},"outputs":[],"source":["# Create a run, which is like saying, we want our model to run and be displayed with these parameters\n","wandb.init(\n","    project='Training 04, Augmenatation and Custom datasets',\n","    config={\n","        'learning rate':0.001,\n","        'architecture': 'cnn',\n","        'dataset': 'Food101 subclass',\n","        'epochs':5,\n","    },\n","    name='with augmentation'\n",")\n","\n","# This is a substitute for logging within the epoch loop as we don't want to change the train function, therefore we can instead deploy the results here right into the logging feature\n","model = model_1_results\n","for i,_ in enumerate(model['train_loss']):\n","  values_at_index = {key: values[i] for key, values in model.items()}\n","  wandb.log(values_at_index)\n","\n","# Simply ends the run\n","wandb.finish()"]},{"cell_type":"markdown","metadata":{"executionInfo":{"elapsed":221,"status":"error","timestamp":1692175267324,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"EKaB6iaVdm64","outputId":"4795ed19-550f-4e68-c3bf-0c034d457b06"},"source":["### Making a prediction on a custom image\n","Although our model isn't perfect, we can still try predicting on it\n","\n","Right now, we have used custom data, but  how do you make a prediction on a sample or image thats chosen by yourself"]},{"cell_type":"markdown","metadata":{"id":"zzkv36bCdpzV"},"source":["##### 1. Get a custom image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cIHBtvu9olds"},"outputs":[],"source":["import torch as pt\n","from sys import path\n","import importLib\n","from pathlib import Path\n","\n","device = 'cuda' if pt.cuda.is_available() else 'cpu'\n","\n","# Download image\n","image_dir = path[0] + '/custom_data'\n","image_path = image_dir+'/04-pizza-dad.jpeg'\n","\n","Path(image_dir).mkdir(exist_ok=True)\n","\n","link = 'https://github.com/mrdbourke/pytorch-deep-learning/raw/main/images/04-pizza-dad.jpeg'\n","importLib.import_from_github(https=link, directory=image_dir)"]},{"cell_type":"markdown","metadata":{"id":"T0_SdSIwolds"},"source":["#### 2. Loadign in a custom image with PyTorch\n","We have to make sure our custom image is in the same format as the model was trained open\n","\n","* In Tensor form\n","* Of shape 64x64x3\n","* On the right device\n","\n","We can read an image into PyTorch as a using: https://pytorch.org/vision/stable/generated/torchvision.io.read_image.html#torchvision.io.read_image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bIxRSCyOolds"},"outputs":[],"source":["import torchvision\n","\n","# print(type(image_path))\n","\n","# uint8 is a format of images\n","# IO stands for Input / Output\n","custom_image_uint8 = torchvision.io.read_image(image_path)\n","\n","# currently in 0-255 as rgb max, model likes 0-1\n","custom_image_uint8 = custom_image_uint8 / 255"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x4ZBL_b5olds"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","plt.imshow(custom_image_uint8.permute(1,2,0))\n","plt.title('custom image')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s5xy5yn2olds"},"outputs":[],"source":["print(r\"As you can see here the image's shape is not 3x64x64 which the model wants\")\n","print(f'Custom image: {custom_image_uint8.shape}')\n","try:\n","    print(f'Model image: {train_dataset[0][0].shape}')\n","except NameError as e:\n","    print(e)\n"]},{"cell_type":"markdown","metadata":{"id":"pDjcOtYqoldt"},"source":["### Making a prediction on a custom image with trained PyTorch model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"87KiIU4gynsU"},"outputs":[],"source":["from torchvision import transforms\n","\n","print(custom_image_uint8.shape)\n","print('As you can see our image has too many pixels, because it wants 64x64, but gets 4032x4032')\n","print('Before we have used transforms to change shape and we will do so again')\n","\n","# Create transform pipeline to resize our image\n","custom_image_transform = transforms.Compose([transforms.Resize((64,64), antialias=None)])\n","\n","# Transform target image\n","custom_image_transformed = custom_image_transform(custom_image_uint8)\n","\n","print(f'After transformation {custom_image_transformed.shape}')\n"]},{"cell_type":"markdown","metadata":{"id":"TqAbinPV0J8F"},"source":["##### plot our transformed image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k9GwMaSq0N9H"},"outputs":[],"source":["print('As you can see our image is a bit squished')\n","plt.imshow(custom_image_transformed.permute(1,2,0))\n","plt.title('Transformed image')\n","pass"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vSy-MVpdoldt"},"outputs":[],"source":["model = model_1\n","with pt.inference_mode():\n","    y_logits = model(custom_image_transformed.to(device).unsqueeze(0))\n","    pred = pt.argmax(pt.softmax(y_logits, dim=1), dim=1)\n","print(f'Our model predicts that our image is a: {train_dataset.classes[pred]}')"]},{"cell_type":"markdown","metadata":{"id":"ERDPZqpeoldt"},"source":["### Functionize our prediction maker"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZuvHrzFB4YL6"},"outputs":[],"source":["def pred_and_plot_image(model:pt.nn.Module, image_path:str, device:pt.device, class_names: list[str] = None, transform: torchvision.transforms=None):\n","    \"\"\"Makes a prediction on a target image with a trained model and plots the image and prediction\"\"\"\n","    target_image = torchvision.io.read_image(str(image_path)).type(pt.float32)\n","\n","    # Devide the image pixel values by 255 to get them between 0-1\n","    target_image/=255.\n","\n","    # Transform our image if necessary\n","    if transform:\n","        target_image = transform(target_image)\n","\n","    model.to(device)\n","    model.eval()\n","    with pt.inference_mode():\n","\n","        # Make a prediction on the image\n","        logits = model(target_image.to(device).unsqueeze(dim=0))\n","    # Convert the logits to pred probs\n","    pred_probs = pt.softmax(logits, dim=1)\n","\n","    # Convert our prediction probabilities -> prediction labels\n","    target_image_pred_label = pt.argmax(pred_probs, dim=1)\n","\n","    # Plot our image alongside the prediction and prediction probability\n","    plt.imshow(target_image.permute(1,2,0))\n","    if class_names:\n","        title=f'Pred: {class_names[target_image_pred_label.cpu()]} | Prob: {pred_probs.max().cpu():.3f}'\n","    else:\n","        title=f'Pred: {target_image_pred_label.cpu().item()} | Prob: {pred_probs.max().cpu():.3f}'\n","    plt.title(title)\n","    plt.axis(False)\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BBh7ur_d4cnV"},"outputs":[],"source":["pred_and_plot_image(\n","    model=model_1,\n","    image_path=image_path,\n","    device=device,\n","    class_names = train_dataset.classes,\n","    transform = custom_image_transform)\n","pass"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3EBtnu-L4ctc"},"outputs":[],"source":["str(image_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p3zXac41d8uC"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["WHUYnvoRT_Os","Mn8lma6QT_Ov","KzRce1X9T_Oz","vw7c4NLQVB6Q"],"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.1"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}