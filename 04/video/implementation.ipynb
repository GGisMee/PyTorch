{"cells":[{"cell_type":"markdown","metadata":{"id":"WHUYnvoRT_Os"},"source":["### Imports"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1692275075815,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"p1WWYmzXT_Ou","outputId":"bf92b0a8-6321-47e8-9440-ce7d3a484512"},"outputs":[{"name":"stdout","output_type":"stream","text":["Torch version: 2.0.1\n","device: cpu\n"]}],"source":["# Imports\n","import torch as pt\n","from torch import nn\n","\n","print(f\"Torch version: {pt.__version__}\")\n","\n","# if pt.cuda.is_available():\n","#     device = 'cuda'\n","# if pt.backends.mps.is_available():\n","#     device = 'mps'\n","# else:\n","#     device= 'cpu'\n","device = 'cpu'\n","print(f'device: {device}')"]},{"cell_type":"markdown","metadata":{"id":"Mn8lma6QT_Ov"},"source":["### Downloading a custom dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1316,"status":"ok","timestamp":1692275077128,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"0FXgAgVmT_Ov","outputId":"0f9056fc-1537-4eb8-b72c-42aec2272dec"},"outputs":[{"name":"stdout","output_type":"stream","text":["Already exists\n","/Users/gustavgamstedt/Desktop/github to hemma/PyTorch/04/video/data/pizza_steak_sushi.zip doesn't exist, download\n","Unzipping pizza, steak and sushi data\n"]}],"source":["from pathlib import Path\n","import importLib\n","from sys import path\n","import zipfile\n","\n","\n","# Create directory\n","data_path = Path(f\"{path[0]}/data\")\n","image_path = data_path / 'pizza_steak_sushi'\n","if image_path.exists():\n","    print('Already exists')\n","else:\n","    image_path.mkdir(parents=True)\n","\n","\n","# Download pizza, steak and sushi data\n","# open skapar en zip fil som sedan fylls genom request\n","importLib.import_from_github('https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip',directory=data_path)\n","with zipfile.ZipFile(data_path/'pizza_steak_sushi.zip', 'r') as zip_ref:\n","    print('Unzipping pizza, steak and sushi data')\n","    zip_ref.extractall(image_path)\n","Path.unlink(data_path/'pizza_steak_sushi.zip')\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1692275077129,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"BCf41f1hT_Ov","outputId":"7bf27311-502b-4658-885b-18d215ae8ea2"},"outputs":[{"data":{"text/plain":["(PosixPath('/Users/gustavgamstedt/Desktop/github to hemma/PyTorch/04/video/data/pizza_steak_sushi/train'),\n"," PosixPath('/Users/gustavgamstedt/Desktop/github to hemma/PyTorch/04/video/data/pizza_steak_sushi/test'))"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Setup training and testing paths\n","train_dir = image_path / 'train'\n","test_dir = image_path / 'test'\n","\n","train_dir, test_dir"]},{"cell_type":"markdown","metadata":{"id":"EMvNq3QJT_Ow"},"source":["### Create dataset and dataloaders"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":316,"status":"ok","timestamp":1692275077443,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"VLcjS6k8T_Ow"},"outputs":[],"source":["from torchvision import transforms\n","simple_transform = transforms.Compose([\n","    transforms.Resize((64,64)),\n","    transforms.ToTensor(),\n","])"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1692275077443,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"-79l2SV0T_Ow"},"outputs":[],"source":["from torchvision import datasets\n","\n","train_dataset = datasets.ImageFolder(root = train_dir, transform=simple_transform)\n","test_dataset = datasets.ImageFolder(root = test_dir, transform=simple_transform)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1692275077444,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"N5tb2d8sT_Ow"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","import os\n","BATCH_SIZE = 32\n","NUM_WORKERS = round(os.cpu_count()*(3/4))\n","train_dataloader = DataLoader(\n","    dataset=train_dataset,\n","    batch_size=BATCH_SIZE,\n","    num_workers=NUM_WORKERS,\n","    shuffle=True\n",")\n","\n","test_dataloader = DataLoader(\n","    dataset=test_dataset,\n","    batch_size=BATCH_SIZE,\n","    num_workers=NUM_WORKERS,\n","    shuffle=False\n",")"]},{"cell_type":"markdown","metadata":{"id":"JNO15QLMT_Ox"},"source":["### Create a model without Augmention"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1692275077444,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"pzivTyy5T_Ox"},"outputs":[],"source":["from torch import nn\n","\n","class TinyVGG(nn.Module):\n","    def __init__(self, input_features:int,output_features:int, hidden_units:int=10):\n","        super().__init__()\n","        self.conv_block_1 = nn.Sequential(\n","            nn.Conv2d(input_features, hidden_units,\n","                      kernel_size=3, stride=1, padding=0),\n","            nn.ReLU(),\n","\n","\n","            nn.Conv2d(hidden_units, hidden_units,\n","                      kernel_size=3, stride=1, padding=0),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","\n","        self.conv_block_2 = nn.Sequential(\n","            nn.Conv2d(hidden_units, hidden_units,\n","                      kernel_size=3, stride=1, padding=0),\n","            nn.ReLU(),\n","\n","\n","            nn.Conv2d(hidden_units, hidden_units,\n","                      kernel_size=3, stride=1, padding=0),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","\n","        self.classifier = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(hidden_units*13*13, output_features)\n","        )\n","    def forward(self, X:pt.Tensor) -> pt.Tensor:\n","        X_change = self.conv_block_1(X)\n","        X_change = self.conv_block_2(X_change)\n","        # print(X_change.shape)\n","        X_change = self.classifier(X_change)\n","        return X_change"]},{"cell_type":"markdown","metadata":{"id":"QOlWiDd-T_Ox"},"source":["#### Testing model with random data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1692275077444,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"PfbemaIaT_Ox","outputId":"b4b81d26-0bfe-4a43-c3cf-b5983ae6f97b"},"outputs":[],"source":["pt.manual_seed(42)\n","model0 = TinyVGG(input_features=3, output_features=len(train_dataset.classes), hidden_units=10).to(device)\n","model0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":751,"status":"ok","timestamp":1692275078192,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"QbT6aSU-T_Ox","outputId":"078d6630-feb2-420a-ce31-fbf7c57719f1"},"outputs":[],"source":["imgs, labels = next(iter(train_dataloader))\n","print(imgs.shape, len(labels))\n","# model0(imgs[0].unsqueeze(0))\n","model0(imgs.to(device))"]},{"cell_type":"markdown","metadata":{"id":"i4njzx4qT_Oy"},"source":["### Summarize a model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4809,"status":"ok","timestamp":1692275082965,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"JNNH266mT_Oy","outputId":"8669e6be-f386-47a0-f0df-b0e00c73476f"},"outputs":[],"source":["try:\n","    import torchinfo\n","except ModuleNotFoundError:\n","    print('Module not found, installing module')\n","    !pip3 install torchinfo\n","    import torchinfo"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1692275083254,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"N5MMfnqvT_Oy","outputId":"4c287e36-5775-47b0-bda5-631085287ab9"},"outputs":[],"source":["torchinfo.summary(model0, input_size=[32,3,64,64],device=device)"]},{"cell_type":"markdown","metadata":{"id":"l0qsPkCIT_Oy"},"source":["### Create train and test loop functions"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1692275083254,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"pVZTGZQ0T_Oy"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","def train_step(model: pt.nn.Module,\n","               dataloader:DataLoader,\n","               loss_fn: pt.nn.Module,\n","               optimizer:pt.optim.Optimizer,\n","               device:pt.device,\n","               show:bool=False):\n","    \"\"\"Performs a training step with model trying to learn on data_loader\n","\n","    args:\n","        model: the model which will be trained on\n","        dataloader: A generator like loader for the data\n","        optimizer: Optimizer which optimizes the code through gradient descend\n","        loss_fn: function which calculates how far from the right answer each of the predictions were\n","        accuracy_fn: function which calculates how meny predictions were right\n","        device: chosen device for the neural network to run on (cpu/gpu/tpu)\n","        show: if true display the loss and acc in console\n","\n","    returns:\n","        (loss, accuracy)\"\"\"\n","    # Put model in training mode\n","    model.train()\n","\n","    # Setup train loss and train accuracy values\n","    train_loss, train_acc = 0,0\n","\n","    # Loop through data loader batches\n","    for X,y in dataloader:\n","        # Send data to target device\n","        X,y = X.to(device), y.to(device)\n","\n","        y_logits = model(X)\n","\n","        loss = loss_fn(y_logits, y)\n","        train_loss+=loss.item()\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        y_preds = pt.argmax(pt.softmax(y_logits, dim=1), dim=1) # Softmax is actually unnecessary, but can be useful for visualization and also to give completeness\n","        train_acc += (y_preds == y).sum().item()/len(y_preds)\n","    train_loss /= len(dataloader)\n","    train_acc  /= len(dataloader)\n","\n","    if show:\n","        print(f'Train loss: {train_loss} | Train acc: {train_acc}')\n","    return train_loss, train_acc"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1692275083254,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"YIncxOAQT_Oy"},"outputs":[],"source":["def test_step(model: pt.nn.Module,\n","              dataloader:DataLoader,\n","              loss_fn: pt.nn.Module,\n","              device:pt.device,\n","              show:bool=False):\n","    \"\"\"Performs a testing loop step on model going over data_loader.\n","\n","    args:\n","        model: the model which will be trained on\n","        dataloader: A generator like loader for the data\n","        loss_fn: function which calculates how far from the right answer each of the predictions were\n","        accuracy_fn: function which calculates how meny predictions were right\n","        device: chosen device for the neural network to run on (cpu/gpu/tpu)\n","        show: if true display the loss and acc in console\n","\n","    returns:\n","        (loss, accuracy)\"\"\"\n","    test_acc, test_loss = 0,0\n","\n","    model.eval()\n","    with pt.inference_mode():\n","        for X,y in dataloader:\n","            X,y = X.to(device), y.to(device)\n","            y_logits = model(X)\n","            loss = loss_fn(y_logits, y)\n","            test_loss+=loss.item()\n","\n","            y_preds = pt.argmax(pt.softmax(y_logits, dim=1), dim=1)\n","            test_acc += (y_preds== y).sum().item()/len(y_preds)\n","    test_loss /= len(dataloader)\n","    test_acc  /= len(dataloader)\n","\n","    print(f'Test loss: {test_loss} | Test acc: {test_acc}') if show else None\n","    return test_loss, test_acc"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1692275083255,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"7DoczMZZT_Oz"},"outputs":[],"source":["\n","from tqdm.notebook import tqdm\n","def train(epochs:int, model:pt.nn.Module, train_dataloader:DataLoader, test_dataloader:DataLoader, loss_fn, optimizer:pt.optim.Optimizer, device:pt.device,show:bool):\n","    \"\"\"Trains the model\"\"\"\n","    # Create an empty dictionary to hold results in\n","    results = {\n","        \"train_loss\":[],\n","        \"train_acc\":[],\n","        \"test_loss\":[],\n","        \"test_acc\":[]\n","        }\n","\n","    for epoch in tqdm(range(epochs)):\n","        print(f'Epoch: {epoch}') if show else None\n","        train_loss, train_acc = train_step(\n","            model=model,\n","            dataloader=train_dataloader,\n","            loss_fn=loss_fn,\n","            optimizer=optimizer,\n","            device=device,\n","            show=show)\n","\n","        test_loss, test_acc = test_step(\n","            model=model,\n","            dataloader= test_dataloader,\n","            loss_fn= loss_fn,\n","            device= device,\n","            show=show\n","            )\n","\n","        # Append our values to results\n","        results[\"train_loss\"].append(train_loss); results[\"train_acc\"].append(train_acc)\n","        results[\"test_loss\"].append(test_loss); results[\"test_acc\"].append(test_acc)\n","    return results"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":442,"referenced_widgets":["e00ea5cf75d84513b9bbc523e191358f","52dfa6a2f8a4491e9073d0ba8aa2a8b7","34abb0a8f3584336842bdcf8aa3ebd5d","551d56244ca84445817dcbe21960d783","eef37a4823474d8fb2cd19618d4f6467","b174bd9bd437455386a738063ec9f5de","85554097a11742b4a5f5926d2785c23b","ac6bb1126a754fe6ad85bbe0aa876ff7","f072acb33ff542c49a9e6c4449f47902","2d92cdd2205a41d785c4329dbc6aa0e7","f38ad41e3d004db69cc140aaa8910bb8"]},"executionInfo":{"elapsed":10846,"status":"ok","timestamp":1692275113197,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"Iu52C_y7T_Oz","outputId":"5f9ca329-2af0-497a-e9ea-cb469c44a750"},"outputs":[],"source":["pt.manual_seed(42)\n","pt.cuda.manual_seed(42)\n","\n","# Set number of epochs\n","NUM_EPOCHS = 5\n","\n","# Recreate an instance of TinyVGG\n","model_0 = TinyVGG(3, len(train_dataset.classes), 10).to(device)\n","\n","loss_fn = nn.CrossEntropyLoss()\n","\n","optimizer = pt.optim.Adam(params=model_0.parameters(), lr=0.001)\n","\n","from ml_funcs import Timer\n","timer = Timer()\n","\n","# Train model_0\n","model_0_results = train(\n","    epochs=5,\n","    model=model_0,\n","    train_dataloader=train_dataloader,\n","    test_dataloader=test_dataloader,\n","    loss_fn=loss_fn,\n","    optimizer=optimizer,\n","    device=device,\n","    show=True)\n","timer.show_as_print()\n"]},{"cell_type":"markdown","metadata":{"id":"OsYD7U3YT_Oz"},"source":["### Save and load model + evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1692275113197,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"D2q1pasAT_Oz","outputId":"1825f841-9de3-42b8-a803-b4c2e39bec3b"},"outputs":[],"source":["from sys import path\n","model_path = f'{path[0]}/models'\n","from ml_funcs import save_load, Model_operations\n","\n","# save_load.save_state_dict(model_0, 'ModelWithoutAugmentation0', model_path)\n","try:\n","  loaded_model = save_load.load_state_dict(TinyVGG(3,len(train_dataset.classes), 10), 'ModelWithoutAugmentation0', model_path)\n","except FileNotFoundError:\n","  print('File not found')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1692275113197,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"0sfKddy3T_Oz"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","def plot_loss_curves(results: dict[str, list[float]]):\n","    \"\"\"Plots training curves of a results dictionary\"\"\"\n","    # Get the loss values of the results dictionary\n","\n","    # train results\n","    train_loss = results['train_loss']\n","    train_acc = results['train_acc']\n","\n","    # test results\n","    test_loss = results['test_loss']\n","    test_acc = results['test_acc']\n","\n","    # epochs\n","    epochs = range(len(results['train_loss']))\n","\n","    # Setup a plot\n","    plt.subplot(1,2,1)\n","    plt.plot(epochs, train_loss, label='train loss', color='red')\n","    plt.plot(epochs, test_loss, label='test loss', color='green')\n","    plt.title('Loss')\n","    plt.xlabel('Epochs')\n","    plt.legend()\n","\n","\n","    plt.subplot(1,2,2)\n","    plt.plot(epochs, train_acc, label='train accuracy',color='orange')\n","    plt.plot(epochs, test_acc, label='train accuracy', color='blue')\n","    plt.title('Accuracy')\n","    plt.xlabel('Epochs')\n","    plt.legend()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"executionInfo":{"elapsed":1136,"status":"ok","timestamp":1692275114321,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"s6M68oJQT_Oz","outputId":"c9cd4340-01f5-4d6c-c368-35a873b30374"},"outputs":[],"source":["plot_loss_curves(model_0_results)"]},{"cell_type":"markdown","metadata":{"id":"KzRce1X9T_Oz"},"source":["### Augmented model"]},{"cell_type":"markdown","metadata":{"id":"4NJWYY8mT_O0"},"source":["#### What does an ideal loss curve look line and how do you make your loss curve look ideal?\n","\n","https://developers.google.com/machine-learning/testing-debugging/metrics/interpretic\n","\n","How to see if your model is overfitting or underfitting:\n","\n","**Underfitting:**\n","* The models loss is high and reducing itself slowly\n","\n","**Overfitting:**\n","* Train loss is alot higher than test loss\n"]},{"cell_type":"markdown","metadata":{"id":"kTnaLHxyT_O0"},"source":["Now let's try another modelling experiment this time using the same model as before but with some data augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":193,"status":"ok","timestamp":1692275199774,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"UscSQFNsT_O0"},"outputs":[],"source":["# Create training transform with TrivialAugment\n","from torchvision import transforms\n","train_transform_trivial = transforms.Compose([\n","    transforms.Resize((64,64)),\n","    transforms.TrivialAugmentWide(num_magnitude_bins=31), # between 0-31 in transformation\n","    transforms.ToTensor()\n","])\n","\n","test_transforms_simple = transforms.Compose([\n","    transforms.Resize((64,64))\n","])"]},{"cell_type":"markdown","metadata":{"id":"3xhGAyhaT_O0"},"source":["#### Create train and test Dataset+DataLoaders with data augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1692275200450,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"uIhlFlLcT_O0"},"outputs":[],"source":["from torchvision import datasets\n","from torch.utils.data import DataLoader\n","\n","BATCH_SIZE = 32\n","NUM_WORKERS = round(os.cpu_count()*(3/4))\n","pt.manual_seed(42)\n","\n","# Datasets\n","aug_train_data = datasets.ImageFolder(train_dir, train_transform_trivial)\n","aug_test_data = datasets.ImageFolder(test_dir, train_transform_trivial)\n","\n","# DataLoaders\n","aug_train_dataloader = DataLoader(dataset=aug_train_data, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True)\n","aug_test_dataloader = DataLoader(dataset=aug_test_data, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"OObNORChT_O0"},"source":["#### Create model 1 with data augmenatation, thus change the data, but not really the model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4755,"status":"ok","timestamp":1692275205903,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"WZ8zXkOPT_O0"},"outputs":[],"source":["#### Creat model 1 with data augmentation\n","pt.manual_seed(42)\n","model_1 = TinyVGG(3, len(aug_test_data.classes), 10).to(device)"]},{"cell_type":"markdown","metadata":{"id":"-mbZ5nX0T_O0"},"source":["#### Create the training loop using train() function"]},{"cell_type":"markdown","metadata":{"id":"B7qeh3iuT_O0"},"source":["As we can see our results point out that data augmentation isn't really needed, because our model performs better without data augmentation\n","\n","This can be seen on the loss curvature of model_0 which had a good negative mean gradient (pointed downwards quite much)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":442,"referenced_widgets":["99447cadadc44d6abd5c64eb12b679cf","0a81ae006d1645a1999b5a5349077d1c","1d13d522996a460eb101e56b4d63c3c8","f010ce63274c445199dae3f6e9b5c58d","63b9ec73560442d6bd6bf1db7a354b44","065709ce4b0340de849cad9dd2d0c192","1807aab6d0044385bf68649b3daba36f","af0e8e117b994c8aae7b6749994e528a","784ac607502543cebbffa674376431a4","cbe8144ab04e43e0a3b85722fafe8e4d","2ef44bdb9ac34dfe9dd081b8de4d2e24"]},"executionInfo":{"elapsed":12897,"status":"ok","timestamp":1692275218794,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"ff24itKLT_O0","outputId":"615619db-2362-4fbc-ca97-06c5d8df2dfd"},"outputs":[],"source":["from torch import nn\n","import torch as pt\n","from helper_functions import set_seeds\n","from ml_funcs import Timer, Model_operations\n","set_seeds(42)\n","NUM_EPOCHS = 5\n","\n","# Loss func\n","aug_loss_fn = nn.CrossEntropyLoss()\n","\n","# Optimizer\n","aug_optimizer = pt.optim.Adam(params=model_1.parameters(), lr=0.001)\n","\n","timer = Timer()\n","\n","# Train model 1\n","model_1_results = train(\n","    epochs=NUM_EPOCHS,\n","    model=model_1,\n","    train_dataloader=aug_train_dataloader,\n","    test_dataloader=aug_test_dataloader,\n","    loss_fn=aug_loss_fn,\n","    optimizer=aug_optimizer,\n","    device=device,\n","    show=True)\n","\n","timer.show_as_print()\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"BsWTkR5AT_O1"},"source":["Loss going up indicates something is going bad, to get a better view try with more epochs\n","\n","It looks as our model is both overfitting and underfitting as well, because of how the test_loss is quite a bit higher then our train loss and both are high values far from 0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"executionInfo":{"elapsed":656,"status":"ok","timestamp":1692275219660,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"9W_viOLQT_O1","outputId":"a15e291e-836d-4dd2-d02a-fd504b51f205"},"outputs":[],"source":["plot_loss_curves(model_1_results)"]},{"cell_type":"markdown","metadata":{"id":"vw7c4NLQVB6Q"},"source":["### 10. Compare model results\n","After evaluating our modelling expoeriments on their own, its time to compare them to each other\n","\n","There are a few different ways to do this:\n","1. Hard code it yourself\n","2. Pytorch + Tensorboard: https://pytorch.org/docs/stable/tensorboard.html\n","3. Weights & Biases: https://wandb.ai/site/experiment-tracking\n","4. MlFlow: https://mlflow.org/\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9239,"status":"ok","timestamp":1692262936045,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"vL3ZG633cgts","outputId":"344be748-8cd9-4e62-b821-af7a8b9d54c2"},"outputs":[],"source":["# Import wandb or Weights and Biases\n","try:\n","    import wandb\n","except ModuleNotFoundError:\n","    print('Module not found, installing module')\n","    !pip3 install wandb\n","    import wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lkObHmkNcgts"},"outputs":[],"source":["'Log into the website'\n","wandb.login()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EkMvb-DCcgtt"},"outputs":[],"source":["# Create a run, which is like saying, we want our model to run and be displayed with these parameters\n","wandb.init(\n","    project='Training 04, Augmenatation and Custom datasets',\n","    config={\n","        'learning rate':0.001,\n","        'architecture': 'cnn',\n","        'dataset': 'Food101 subclass',\n","        'epochs':5,\n","    },\n","    name='with augmentation'\n",")\n","\n","# This is a substitute for logging within the epoch loop as we don't want to change the train function, therefore we can instead deploy the results here right into the logging feature\n","model = model_1_results\n","for i,_ in enumerate(model['train_loss']):\n","  values_at_index = {key: values[i] for key, values in model.items()}\n","  wandb.log(values_at_index)\n","\n","# Simply ends the run\n","wandb.finish()"]},{"cell_type":"markdown","metadata":{"executionInfo":{"elapsed":221,"status":"error","timestamp":1692175267324,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"EKaB6iaVdm64","outputId":"4795ed19-550f-4e68-c3bf-0c034d457b06"},"source":["### Making a prediction on a custom image\n","Although our model isn't perfect, we can still try predicting on it\n","\n","Right now, we have used custom data, but  how do you make a prediction on a sample or image thats chosen by yourself"]},{"cell_type":"markdown","metadata":{"id":"zzkv36bCdpzV"},"source":["##### 1. Get a custom image"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":204,"status":"ok","timestamp":1692275262840,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"cIHBtvu9olds","outputId":"214f4e35-5517-4229-eaf0-27ba9405d643"},"outputs":[],"source":["import torch as pt\n","from sys import path\n","import importLib\n","from pathlib import Path\n","\n","device = 'cuda' if pt.cuda.is_available() else 'cpu'\n","\n","# Download image\n","image_dir = path[0] + '/custom_data'\n","image_path = image_dir+'/04-pizza-dad.jpeg'\n","\n","Path(image_dir).mkdir(exist_ok=True)\n","\n","link = 'https://github.com/mrdbourke/pytorch-deep-learning/raw/main/images/04-pizza-dad.jpeg'\n","importLib.import_from_github(https=link, directory=image_dir)"]},{"cell_type":"markdown","metadata":{"id":"T0_SdSIwolds"},"source":["#### 2. Loadign in a custom image with PyTorch\n","We have to make sure our custom image is in the same format as the model was trained open\n","\n","* In Tensor form\n","* Of shape 64x64x3\n","* On the right device\n","\n","We can read an image into PyTorch as a using: https://pytorch.org/vision/stable/generated/torchvision.io.read_image.html#torchvision.io.read_image"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":445,"status":"ok","timestamp":1692275130077,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"bIxRSCyOolds"},"outputs":[],"source":["import torchvision\n","\n","# print(type(image_path))\n","\n","# uint8 is a format of images\n","# IO stands for Input / Output\n","custom_image_uint8 = torchvision.io.read_image(image_path)\n","\n","# currently in 0-255 as rgb max, model likes 0-1\n","custom_image_uint8 = custom_image_uint8 / 255"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":470},"executionInfo":{"elapsed":3446,"status":"ok","timestamp":1692275135358,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"x4ZBL_b5olds","outputId":"d641339d-b104-4f67-a74b-3d74b314aa67"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","plt.imshow(custom_image_uint8.permute(1,2,0))\n","plt.title('custom image')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":212,"status":"ok","timestamp":1692275138825,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"s5xy5yn2olds","outputId":"083dc03c-91f8-4c79-e7e4-9cea1a9af271"},"outputs":[],"source":["print(r\"As you can see here the image's shape is not 3x64x64 which the model wants\")\n","print(f'Custom image: {custom_image_uint8.shape}')\n","try:\n","    print(f'Model image: {train_dataset[0][0].shape}')\n","except NameError as e:\n","    print(e)\n"]},{"cell_type":"markdown","metadata":{"id":"pDjcOtYqoldt"},"source":["### Making a prediction on a custom image with trained PyTorch model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1692275557268,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"87KiIU4gynsU","outputId":"351061da-70d9-465d-97bc-e88ea68401e4"},"outputs":[],"source":["from torchvision import transforms\n","\n","print(custom_image_uint8.shape)\n","print('As you can see our image has too many pixels, because it wants 64x64, but gets 4032x4032')\n","print('Before we have used transforms to change shape and we will do so again')\n","\n","# Create transform pipeline to resize our image\n","custom_image_transform = transforms.Compose([transforms.Resize((64,64), antialias=None)])\n","\n","# Transform target image\n","custom_image_transformed = custom_image_transform(custom_image_uint8)\n","\n","print(f'After transformation {custom_image_transformed.shape}')\n"]},{"cell_type":"markdown","metadata":{"id":"TqAbinPV0J8F"},"source":["##### plot our transformed image"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":470},"executionInfo":{"elapsed":581,"status":"ok","timestamp":1692275560254,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"k9GwMaSq0N9H","outputId":"121e943f-ad92-4675-9f72-22d46e6605ad"},"outputs":[],"source":["print('As you can see our image is a bit squished')\n","plt.imshow(custom_image_transformed.permute(1,2,0))\n","plt.title('Transformed image')\n","pass"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1692275560549,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"vSy-MVpdoldt","outputId":"f5c662c9-61bc-4e09-daf8-646bd2c3d729"},"outputs":[],"source":["model = model_1\n","with pt.inference_mode():\n","    y_logits = model(custom_image_transformed.to(device).unsqueeze(0))\n","    pred = pt.argmax(pt.softmax(y_logits, dim=1), dim=1)\n","print(f'Our model predicts that our image is a: {train_dataset.classes[pred]}')"]},{"cell_type":"markdown","metadata":{"id":"ERDPZqpeoldt"},"source":["### Functionize our prediction maker"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1692275562060,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"ZuvHrzFB4YL6"},"outputs":[],"source":["def pred_and_plot_image(model:pt.nn.Module, image_path:str, device:pt.device, class_names: list[str] = None, transform: torchvision.transforms=None):\n","    \"\"\"Makes a prediction on a target image with a trained model and plots the image and prediction\"\"\"\n","    target_image = torchvision.io.read_image(str(image_path)).type(pt.float32)\n","\n","    # Devide the image pixel values by 255 to get them between 0-1\n","    target_image/=255.\n","\n","    # Transform our image if necessary\n","    if transform:\n","        target_image = transform(target_image)\n","\n","    model.to(device)\n","    model.eval()\n","    with pt.inference_mode():\n","\n","        # Make a prediction on the image\n","        logits = model(target_image.to(device).unsqueeze(dim=0))\n","    # Convert the logits to pred probs\n","    pred_probs = pt.softmax(logits, dim=1)\n","\n","    # Convert our prediction probabilities -> prediction labels\n","    target_image_pred_label = pt.argmax(pred_probs, dim=1)\n","\n","    # Plot our image alongside the prediction and prediction probability\n","    plt.imshow(target_image.permute(1,2,0))\n","    if class_names:\n","        title=f'Pred: {class_names[target_image_pred_label.cpu()]} | Prob: {pred_probs.max().cpu():.3f}'\n","    else:\n","        title=f'Pred: {target_image_pred_label.cpu()} | Prob: {pred_probs.max().cpu():.3f}'\n","    plt.title(title)\n","    plt.axis(False)\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":428},"executionInfo":{"elapsed":605,"status":"ok","timestamp":1692275612759,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"BBh7ur_d4cnV","outputId":"99fe4e6e-2a07-4801-a3f2-493f106c2a84"},"outputs":[],"source":["pred_and_plot_image(\n","    model=model_1,\n","    image_path=image_path,\n","    device=device,\n","    class_names = train_dataset.classes,\n","    transform = custom_image_transform)\n","pass"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":201,"status":"ok","timestamp":1692275297935,"user":{"displayName":"GGisMe","userId":"04154362628936851348"},"user_tz":-120},"id":"3EBtnu-L4ctc","outputId":"be319793-67c6-4623-b060-af7dfafe0c55"},"outputs":[],"source":["str(image_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p3zXac41d8uC"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["WHUYnvoRT_Os","Mn8lma6QT_Ov","KzRce1X9T_Oz","vw7c4NLQVB6Q"],"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.1"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"065709ce4b0340de849cad9dd2d0c192":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a81ae006d1645a1999b5a5349077d1c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_065709ce4b0340de849cad9dd2d0c192","placeholder":"​","style":"IPY_MODEL_1807aab6d0044385bf68649b3daba36f","value":"100%"}},"1807aab6d0044385bf68649b3daba36f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d13d522996a460eb101e56b4d63c3c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_af0e8e117b994c8aae7b6749994e528a","max":5,"min":0,"orientation":"horizontal","style":"IPY_MODEL_784ac607502543cebbffa674376431a4","value":5}},"2d92cdd2205a41d785c4329dbc6aa0e7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ef44bdb9ac34dfe9dd081b8de4d2e24":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"34abb0a8f3584336842bdcf8aa3ebd5d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac6bb1126a754fe6ad85bbe0aa876ff7","max":5,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f072acb33ff542c49a9e6c4449f47902","value":5}},"52dfa6a2f8a4491e9073d0ba8aa2a8b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b174bd9bd437455386a738063ec9f5de","placeholder":"​","style":"IPY_MODEL_85554097a11742b4a5f5926d2785c23b","value":"100%"}},"551d56244ca84445817dcbe21960d783":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d92cdd2205a41d785c4329dbc6aa0e7","placeholder":"​","style":"IPY_MODEL_f38ad41e3d004db69cc140aaa8910bb8","value":" 5/5 [00:10&lt;00:00,  2.34s/it]"}},"63b9ec73560442d6bd6bf1db7a354b44":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"784ac607502543cebbffa674376431a4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"85554097a11742b4a5f5926d2785c23b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"99447cadadc44d6abd5c64eb12b679cf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0a81ae006d1645a1999b5a5349077d1c","IPY_MODEL_1d13d522996a460eb101e56b4d63c3c8","IPY_MODEL_f010ce63274c445199dae3f6e9b5c58d"],"layout":"IPY_MODEL_63b9ec73560442d6bd6bf1db7a354b44"}},"ac6bb1126a754fe6ad85bbe0aa876ff7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af0e8e117b994c8aae7b6749994e528a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b174bd9bd437455386a738063ec9f5de":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbe8144ab04e43e0a3b85722fafe8e4d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e00ea5cf75d84513b9bbc523e191358f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_52dfa6a2f8a4491e9073d0ba8aa2a8b7","IPY_MODEL_34abb0a8f3584336842bdcf8aa3ebd5d","IPY_MODEL_551d56244ca84445817dcbe21960d783"],"layout":"IPY_MODEL_eef37a4823474d8fb2cd19618d4f6467"}},"eef37a4823474d8fb2cd19618d4f6467":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f010ce63274c445199dae3f6e9b5c58d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cbe8144ab04e43e0a3b85722fafe8e4d","placeholder":"​","style":"IPY_MODEL_2ef44bdb9ac34dfe9dd081b8de4d2e24","value":" 5/5 [00:12&lt;00:00,  1.74s/it]"}},"f072acb33ff542c49a9e6c4449f47902":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f38ad41e3d004db69cc140aaa8910bb8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
