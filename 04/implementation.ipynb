{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.0.1\n",
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import torch as pt\n",
    "from torch import nn\n",
    "\n",
    "print(f\"Torch version: {pt.__version__}\")\n",
    "\n",
    "# if pt.cuda.is_available():\n",
    "#     device = 'cuda'\n",
    "# if pt.backends.mps.is_available():\n",
    "#     device = 'mps'\n",
    "# else:\n",
    "#     device= 'cpu'\n",
    "device = 'cpu'\n",
    "print(f'device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading a custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already exists\n",
      "/Users/gustavgamstedt/Desktop/github to hemma/PyTorch/04/data/pizza_steak_sushi.zip doesn't exist, download\n",
      "Unzipping pizza, steak and sushi data\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import importLib\n",
    "from sys import path\n",
    "import zipfile\n",
    "\n",
    "\n",
    "# Create directory\n",
    "data_path = Path(f\"{path[0]}/data\")\n",
    "image_path = data_path / 'pizza_steak_sushi'\n",
    "if image_path.exists():\n",
    "    print('Already exists')\n",
    "else:\n",
    "    image_path.mkdir(parents=True)\n",
    "\n",
    "\n",
    "# Download pizza, steak and sushi data\n",
    "# open skapar en zip fil som sedan fylls genom request\n",
    "importLib.import_from_github('https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip',directory=data_path)\n",
    "with zipfile.ZipFile(data_path/'pizza_steak_sushi.zip', 'r') as zip_ref:\n",
    "    print('Unzipping pizza, steak and sushi data')\n",
    "    zip_ref.extractall(image_path)\n",
    "Path.unlink(data_path/'pizza_steak_sushi.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/Users/gustavgamstedt/Desktop/github to hemma/PyTorch/04/data/pizza_steak_sushi/train'),\n",
       " PosixPath('/Users/gustavgamstedt/Desktop/github to hemma/PyTorch/04/data/pizza_steak_sushi/test'))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup training and testing paths\n",
    "train_dir = image_path / 'train'\n",
    "test_dir = image_path / 'test'\n",
    "\n",
    "train_dir, test_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "simple_transform = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root = train_dir, transform=simple_transform)\n",
    "test_dataset = datasets.ImageFolder(root = test_dir, transform=simple_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = round(os.cpu_count()*(3/4))\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=32,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=32,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class ModelWithoutAugmentation(nn.Module):\n",
    "    def __init__(self, input_features:int,output_features:int, hidden_units:int=10):\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(input_features, hidden_units,\n",
    "                      kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "\n",
    "\n",
    "            nn.Conv2d(hidden_units, hidden_units,\n",
    "                      kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units, hidden_units,\n",
    "                      kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "\n",
    "\n",
    "            nn.Conv2d(hidden_units, hidden_units,\n",
    "                      kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(hidden_units*13*13, output_features)\n",
    "        )\n",
    "    def forward(self, X:pt.Tensor) -> pt.Tensor:\n",
    "        X_change = self.conv_block_1(X)\n",
    "        X_change = self.conv_block_2(X_change)\n",
    "        # print(X_change.shape)\n",
    "        X_change = self.classifier(X_change)\n",
    "        return X_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelWithoutAugmentation(\n",
       "  (conv_block_1): Sequential(\n",
       "    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv_block_2): Sequential(\n",
       "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=1690, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.manual_seed(42)\n",
    "model0 = ModelWithoutAugmentation(input_features=3, output_features=len(train_dataset.classes), hidden_units=10).to(device)\n",
    "model0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing model with random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 64, 64]) 32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.0795e-02, -1.9510e-03,  9.5212e-03],\n",
       "        [ 1.8440e-02,  2.4668e-03,  6.6609e-03],\n",
       "        [ 1.7695e-02,  1.0282e-03,  9.4975e-03],\n",
       "        [ 2.4446e-02, -3.3489e-03,  9.5877e-03],\n",
       "        [ 1.9939e-02,  6.9129e-04,  1.0778e-02],\n",
       "        [ 2.1281e-02,  2.0434e-03,  5.0047e-03],\n",
       "        [ 2.0996e-02,  1.6414e-04,  1.2481e-02],\n",
       "        [ 2.1566e-02, -1.9607e-03,  9.7175e-03],\n",
       "        [ 2.4500e-02, -4.7904e-03,  8.5394e-03],\n",
       "        [ 2.0239e-02, -4.7979e-04,  1.0907e-02],\n",
       "        [ 2.2219e-02, -4.1815e-04,  9.8173e-03],\n",
       "        [ 2.2318e-02, -2.1642e-03,  9.4428e-03],\n",
       "        [ 2.1851e-02, -3.7225e-03,  8.3784e-03],\n",
       "        [ 2.2881e-02, -1.7559e-03,  1.0299e-02],\n",
       "        [ 2.1635e-02, -4.3995e-03,  9.4989e-03],\n",
       "        [ 2.2101e-02, -4.1470e-03,  9.3903e-03],\n",
       "        [ 2.1226e-02, -4.4215e-03,  1.1476e-02],\n",
       "        [ 2.1698e-02, -2.7458e-03,  8.4966e-03],\n",
       "        [ 1.9974e-02, -3.2037e-07,  8.4496e-03],\n",
       "        [ 1.8308e-02,  1.6378e-03,  8.5490e-03],\n",
       "        [ 2.0768e-02,  1.8096e-03,  7.9825e-03],\n",
       "        [ 1.9826e-02, -3.8645e-03,  9.8465e-03],\n",
       "        [ 2.0900e-02,  1.2143e-04,  8.3933e-03],\n",
       "        [ 2.3190e-02, -3.4667e-03,  9.4969e-03],\n",
       "        [ 2.0510e-02, -2.5316e-03,  8.4688e-03],\n",
       "        [ 1.8149e-02,  2.0775e-03,  8.2082e-03],\n",
       "        [ 2.0323e-02, -1.7798e-03,  7.8779e-03],\n",
       "        [ 1.7277e-02, -3.2317e-04,  1.2488e-02],\n",
       "        [ 1.8340e-02, -1.5345e-03,  9.4628e-03],\n",
       "        [ 1.9844e-02, -2.3284e-03,  9.0066e-03],\n",
       "        [ 2.2059e-02, -4.6367e-03,  1.2652e-02],\n",
       "        [ 1.8056e-02,  2.6729e-03,  5.8030e-03]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs, labels = next(iter(train_dataloader))\n",
    "print(imgs.shape, len(labels))\n",
    "# model0(imgs[0].unsqueeze(0))\n",
    "model0(imgs.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import torchinfo\n",
    "except ModuleNotFoundError:\n",
    "    print('Module not found, installing module')\n",
    "    !pip3 install torchinfo\n",
    "    import torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ModelWithoutAugmentation                 [32, 3]                   --\n",
       "├─Sequential: 1-1                        [32, 10, 30, 30]          --\n",
       "│    └─Conv2d: 2-1                       [32, 10, 62, 62]          280\n",
       "│    └─ReLU: 2-2                         [32, 10, 62, 62]          --\n",
       "│    └─Conv2d: 2-3                       [32, 10, 60, 60]          910\n",
       "│    └─ReLU: 2-4                         [32, 10, 60, 60]          --\n",
       "│    └─MaxPool2d: 2-5                    [32, 10, 30, 30]          --\n",
       "├─Sequential: 1-2                        [32, 10, 13, 13]          --\n",
       "│    └─Conv2d: 2-6                       [32, 10, 28, 28]          910\n",
       "│    └─ReLU: 2-7                         [32, 10, 28, 28]          --\n",
       "│    └─Conv2d: 2-8                       [32, 10, 26, 26]          910\n",
       "│    └─ReLU: 2-9                         [32, 10, 26, 26]          --\n",
       "│    └─MaxPool2d: 2-10                   [32, 10, 13, 13]          --\n",
       "├─Sequential: 1-3                        [32, 3]                   --\n",
       "│    └─Flatten: 2-11                     [32, 1690]                --\n",
       "│    └─Linear: 2-12                      [32, 3]                   5,073\n",
       "==========================================================================================\n",
       "Total params: 8,083\n",
       "Trainable params: 8,083\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 181.95\n",
       "==========================================================================================\n",
       "Input size (MB): 1.57\n",
       "Forward/backward pass size (MB): 22.80\n",
       "Params size (MB): 0.03\n",
       "Estimated Total Size (MB): 24.40\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchinfo.summary(model0, input_size=[32,3,64,64],device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train and test loop functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "def train_step(model: pt.nn.Module, \n",
    "               dataloader:DataLoader, \n",
    "               loss_fn: pt.nn.Module, \n",
    "               optimizer:pt.optim.Optimizer, \n",
    "               device:pt.device, \n",
    "               show:bool=False):\n",
    "    \"\"\"Performs a training step with model trying to learn on data_loader\n",
    "\n",
    "    args:\n",
    "        model: the model which will be trained on\n",
    "        dataloader: A generator like loader for the data\n",
    "        optimizer: Optimizer which optimizes the code through gradient descend\n",
    "        loss_fn: function which calculates how far from the right answer each of the predictions were\n",
    "        accuracy_fn: function which calculates how meny predictions were right\n",
    "        device: chosen device for the neural network to run on (cpu/gpu/tpu)\n",
    "        show: if true display the loss and acc in console \n",
    "        \n",
    "    returns:\n",
    "        (loss, accuracy)\"\"\"\n",
    "    # Put model in training mode\n",
    "    model.train()\n",
    "     \n",
    "    # Setup train loss and train accuracy values\n",
    "    train_loss, train_acc = 0,0\n",
    "\n",
    "    # Loop through data loader batches\n",
    "    for X,y in dataloader:\n",
    "        # Send data to target device\n",
    "        X,y = X.to(device), y.to(device)\n",
    "\n",
    "        y_logits = model(X)\n",
    "        \n",
    "        loss = loss_fn(y_logits, y)\n",
    "        train_loss+=loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        y_preds = pt.argmax(pt.softmax(y_logits, dim=1), dim=1) # Softmax is actually unnecessary, but can be useful for visualization and also to give completeness\n",
    "        train_acc += (y_preds == y).sum().item()/len(y_preds)\n",
    "    train_loss /= len(dataloader)\n",
    "    train_acc  /= len(dataloader)\n",
    "\n",
    "    if show:\n",
    "        print(f'Train loss: {train_loss} | Train acc: {train_acc}')\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model: pt.nn.Module, \n",
    "              dataloader:DataLoader, \n",
    "              loss_fn: pt.nn.Module, \n",
    "              device:pt.device, \n",
    "              show:bool=False):\n",
    "    \"\"\"Performs a testing loop step on model going over data_loader.\n",
    "\n",
    "    args:\n",
    "        model: the model which will be trained on\n",
    "        dataloader: A generator like loader for the data\n",
    "        loss_fn: function which calculates how far from the right answer each of the predictions were\n",
    "        accuracy_fn: function which calculates how meny predictions were right\n",
    "        device: chosen device for the neural network to run on (cpu/gpu/tpu)\n",
    "        show: if true display the loss and acc in console \n",
    "\n",
    "    returns:\n",
    "        (loss, accuracy)\"\"\"\n",
    "    test_acc, test_loss = 0,0\n",
    "    \n",
    "    model.eval()\n",
    "    with pt.inference_mode():\n",
    "        for X,y in dataloader:\n",
    "            X,y = X.to(device), y.to(device)\n",
    "            y_logits = model(X)\n",
    "            loss = loss_fn(y_logits, y)\n",
    "            test_loss+=loss.item()\n",
    "\n",
    "            y_preds = pt.argmax(pt.softmax(y_logits, dim=1), dim=1)\n",
    "            test_acc += (y_preds== y).sum().item()/len(y_preds)\n",
    "    test_loss /= len(dataloader)\n",
    "    test_acc  /= len(dataloader)\n",
    "    \n",
    "    print(f'Test loss: {test_loss} | Test acc: {test_acc}') if show else None\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm.notebook import tqdm\n",
    "def train(epochs:int, model:pt.nn.Module, train_dataloader:DataLoader, test_dataloader:DataLoader, loss_fn, optimizer:pt.optim.Optimizer, device:pt.device,show:bool):\n",
    "    # Create an empty dictionary to hold results in\n",
    "    results = {\n",
    "        \"train_loss\":[], \n",
    "        \"train_acc\":[], \n",
    "        \"test_loss\":[], \n",
    "        \"test_acc\":[]\n",
    "        }\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        print(f'Epoch: {epoch}') if show else None\n",
    "        train_loss, train_acc = train_step(\n",
    "            model=model,\n",
    "            dataloader=train_dataloader,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            device=device,\n",
    "            show=show)\n",
    "            \n",
    "        test_loss, test_acc = test_step(\n",
    "            model=model, \n",
    "            dataloader= test_dataloader, \n",
    "            loss_fn= loss_fn, \n",
    "            device= device, \n",
    "            show=show\n",
    "            )\n",
    "        \n",
    "        # Append our values to results\n",
    "        results[\"train_loss\"].append(train_loss); results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss); results[\"test_acc\"].append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81d400b72e7d46cf8c81e0c6d722f964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    }
   ],
   "source": [
    "pt.manual_seed(42)\n",
    "pt.cuda.manual_seed(42)\n",
    "\n",
    "# Set number of epochs\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "# Recreate an instance of TinyVGG\n",
    "model_0 = ModelWithoutAugmentation(3, len(train_dataset.classes), 10).to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = pt.optim.Adam(params=model_0.parameters(), lr=0.001)\n",
    "\n",
    "from ml_funcs import Timer\n",
    "timer = Timer()\n",
    "\n",
    "# Train model_0\n",
    "model_0_results = train(\n",
    "    epochs=5,\n",
    "    model=model_0,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    show=True)\n",
    "timer.show_as_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'ModelWithoutAugmentation',\n",
       " 'model_loss': 1.0976074934005737,\n",
       " 'model_acc': 0.2604166666666667}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ml_funcs import Model_operations\n",
    "Model_operations.eval_model(model_0, test_dataloader, loss_fn, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
