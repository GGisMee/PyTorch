{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/04_pytorch_custom_datasets_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vex99np2wFVt"
      },
      "source": [
        "# 04. PyTorch Custom Datasets Exercises Template\n",
        "\n",
        "Welcome to the 04. PyTorch Custom Datasets exercise template.\n",
        "\n",
        "The best way to practice PyTorch code is to write more PyTorch code.\n",
        "\n",
        "So read the original notebook and try to complete the exercises by writing code where it's required.\n",
        "\n",
        "Feel free to reference the original resources whenever you need but should practice writing all of the code yourself.\n",
        "\n",
        "## Resources\n",
        "\n",
        "1. These exercises/solutions are based on [notebook 04 of the Learn PyTorch for Deep Learning course](https://www.learnpytorch.io/04_pytorch_custom_datasets/).\n",
        "2. See a live [walkthrough of the solutions (errors and all) on YouTube](https://youtu.be/vsFMF9wqWx0).\n",
        "3. See [other solutions on the course GitHub](https://github.com/mrdbourke/pytorch-deep-learning/tree/main/extras/solutions)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GaeYzOTLwWh2",
        "outputId": "14673108-7705-4e73-b7bc-d94bf9c96423"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: nvidia-smi\n"
          ]
        }
      ],
      "source": [
        "# Check for GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "DNwZLMbCzJLk",
        "outputId": "1a7b73e2-ec4b-41b0-b4da-c3216a8a29ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.0.1\n"
          ]
        }
      ],
      "source": [
        "# Import pt\n",
        "import torch as pt\n",
        "from torch import nn\n",
        "\n",
        "# Exercises require PyTorch > 1.10.0\n",
        "print(pt.__version__)\n",
        "\n",
        "# Setup device agnostic code\n",
        "device = \"cuda\" if pt.cuda.is_available() else \"cpu\"\n",
        "device\n",
        "pt.set_default_device(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSFX7tc1w-en"
      },
      "source": [
        "## 1. Our models are underperforming (not fitting the data well). What are 3 methods for preventing underfitting? Write them down and explain each with a sentence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-90Qvx9gtrLj"
      },
      "source": [
        "1. Increase the size of the dataset\n",
        "2. Increase the number of nodes and layer stacks\n",
        "3. Decrease data augmentation\n",
        "4. Increase the amount of training on the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBK-WI6YxDYa"
      },
      "source": [
        "## 2. Recreate the data loading functions we built in [sections 1, 2, 3 and 4 of notebook 04](https://www.learnpytorch.io/04_pytorch_custom_datasets/). You should have train and test `DataLoader`'s ready to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MZkCPJBR3lw4"
      },
      "outputs": [],
      "source": [
        "# 1. Get data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TYmhAX7J52VX"
      },
      "outputs": [],
      "source": [
        "# 2. Become one with the data\n",
        "import os\n",
        "def walk_through_dir(dir_path):\n",
        "  \"\"\"Walks through dir_path returning file counts of its contents.\"\"\"\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3A9ZmOn-7Jhh"
      },
      "outputs": [],
      "source": [
        "# Setup train and testing paths\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "51ywNKkN7WOl"
      },
      "outputs": [],
      "source": [
        "# Visualize an image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Qe4LoASC9sQ-"
      },
      "outputs": [],
      "source": [
        "# Do the image visualization with matplotlib\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AU4FGYC_KBz"
      },
      "source": [
        "We've got some images in our folders.\n",
        "\n",
        "Now we need to make them compatible with PyTorch by:\n",
        "1. Transform the data into tensors.\n",
        "2. Turn the tensor data into a `pt.utils.data.Dataset` and later a `pt.utils.data.DataLoader`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KbGMaYGT-vwq"
      },
      "outputs": [],
      "source": [
        "# 3.1 Transforming data with torchvision.transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gnvUSYYW_ohN"
      },
      "outputs": [],
      "source": [
        "# Write transform for turning images into tensors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vp8I2cpMAxcT"
      },
      "outputs": [],
      "source": [
        "# Write a function to plot transformed images\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKgfqPArChVR"
      },
      "source": [
        "### Load image data using `ImageFolder`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Already exists\n",
            "/Users/gustavgamstedt/Desktop/github to hemma/PyTorch/04/exercises/data/pizza_steak_sushi.zip doesn't exist, download\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 19\u001b[0m\n\u001b[1;32m     14\u001b[0m     image_path\u001b[39m.\u001b[39mmkdir(parents\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m \u001b[39m# Download pizza, steak and sushi data\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m# open skapar en zip fil som sedan fylls genom request\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m importLib\u001b[39m.\u001b[39;49mimport_from_github(\u001b[39m'\u001b[39;49m\u001b[39mhttps://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\u001b[39;49m\u001b[39m'\u001b[39;49m,directory\u001b[39m=\u001b[39;49mdata_path)\n\u001b[1;32m     20\u001b[0m \u001b[39mwith\u001b[39;00m zipfile\u001b[39m.\u001b[39mZipFile(data_path\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpizza_steak_sushi.zip\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m zip_ref:\n\u001b[1;32m     21\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mUnzipping pizza, steak and sushi data\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[0;32m~/Desktop/github to hemma/PyTorch/04/exercises/importLib.py:30\u001b[0m, in \u001b[0;36mimport_from_github\u001b[0;34m(https, file_name, directory, load_lib)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfile_path\u001b[39m}\u001b[39;00m\u001b[39m doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt exist, download\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     request \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(https)\n\u001b[1;32m     31\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mMissingSchema:\n\u001b[1;32m     32\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mURL not found\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/sessions.py:579\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    575\u001b[0m prep \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_request(req)\n\u001b[1;32m    577\u001b[0m proxies \u001b[39m=\u001b[39m proxies \u001b[39mor\u001b[39;00m {}\n\u001b[0;32m--> 579\u001b[0m settings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmerge_environment_settings(\n\u001b[1;32m    580\u001b[0m     prep\u001b[39m.\u001b[39;49murl, proxies, stream, verify, cert\n\u001b[1;32m    581\u001b[0m )\n\u001b[1;32m    583\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/sessions.py:761\u001b[0m, in \u001b[0;36mSession.merge_environment_settings\u001b[0;34m(self, url, proxies, stream, verify, cert)\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrust_env:\n\u001b[1;32m    759\u001b[0m     \u001b[39m# Set environment's proxies.\u001b[39;00m\n\u001b[1;32m    760\u001b[0m     no_proxy \u001b[39m=\u001b[39m proxies\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mno_proxy\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mif\u001b[39;00m proxies \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 761\u001b[0m     env_proxies \u001b[39m=\u001b[39m get_environ_proxies(url, no_proxy\u001b[39m=\u001b[39;49mno_proxy)\n\u001b[1;32m    762\u001b[0m     \u001b[39mfor\u001b[39;00m (k, v) \u001b[39min\u001b[39;00m env_proxies\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    763\u001b[0m         proxies\u001b[39m.\u001b[39msetdefault(k, v)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/utils.py:830\u001b[0m, in \u001b[0;36mget_environ_proxies\u001b[0;34m(url, no_proxy)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_environ_proxies\u001b[39m(url, no_proxy\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    825\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[39m    Return a dict of environment proxies.\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \n\u001b[1;32m    828\u001b[0m \u001b[39m    :rtype: dict\u001b[39;00m\n\u001b[1;32m    829\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 830\u001b[0m     \u001b[39mif\u001b[39;00m should_bypass_proxies(url, no_proxy\u001b[39m=\u001b[39;49mno_proxy):\n\u001b[1;32m    831\u001b[0m         \u001b[39mreturn\u001b[39;00m {}\n\u001b[1;32m    832\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/utils.py:814\u001b[0m, in \u001b[0;36mshould_bypass_proxies\u001b[0;34m(url, no_proxy)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[39mwith\u001b[39;00m set_environ(\u001b[39m\"\u001b[39m\u001b[39mno_proxy\u001b[39m\u001b[39m\"\u001b[39m, no_proxy_arg):\n\u001b[1;32m    812\u001b[0m     \u001b[39m# parsed.hostname can be `None` in cases such as a file URI.\u001b[39;00m\n\u001b[1;32m    813\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 814\u001b[0m         bypass \u001b[39m=\u001b[39m proxy_bypass(parsed\u001b[39m.\u001b[39;49mhostname)\n\u001b[1;32m    815\u001b[0m     \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, socket\u001b[39m.\u001b[39mgaierror):\n\u001b[1;32m    816\u001b[0m         bypass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:2654\u001b[0m, in \u001b[0;36mproxy_bypass\u001b[0;34m(host)\u001b[0m\n\u001b[1;32m   2652\u001b[0m     \u001b[39mreturn\u001b[39;00m proxy_bypass_environment(host, proxies)\n\u001b[1;32m   2653\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2654\u001b[0m     \u001b[39mreturn\u001b[39;00m proxy_bypass_macosx_sysconf(host)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:2631\u001b[0m, in \u001b[0;36mproxy_bypass_macosx_sysconf\u001b[0;34m(host)\u001b[0m\n\u001b[1;32m   2629\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mproxy_bypass_macosx_sysconf\u001b[39m(host):\n\u001b[1;32m   2630\u001b[0m     proxy_settings \u001b[39m=\u001b[39m _get_proxy_settings()\n\u001b[0;32m-> 2631\u001b[0m     \u001b[39mreturn\u001b[39;00m _proxy_bypass_macosx_sysconf(host, proxy_settings)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/request.py:2602\u001b[0m, in \u001b[0;36m_proxy_bypass_macosx_sysconf\u001b[0;34m(host, proxy_settings)\u001b[0m\n\u001b[1;32m   2600\u001b[0m         hostIP \u001b[39m=\u001b[39m ip2num(hostIP)\n\u001b[1;32m   2601\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[0;32m-> 2602\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m   2604\u001b[0m base \u001b[39m=\u001b[39m ip2num(m\u001b[39m.\u001b[39mgroup(\u001b[39m1\u001b[39m))\n\u001b[1;32m   2605\u001b[0m mask \u001b[39m=\u001b[39m m\u001b[39m.\u001b[39mgroup(\u001b[39m2\u001b[39m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Create dataset\n",
        "from pathlib import Path\n",
        "import importLib\n",
        "from sys import path\n",
        "import zipfile\n",
        "\n",
        "\n",
        "# Create directory\n",
        "data_path = Path(f\"{path[0]}/data\")\n",
        "image_path = data_path / 'pizza_steak_sushi'\n",
        "if image_path.exists():\n",
        "    print('Already exists')\n",
        "else:\n",
        "    image_path.mkdir(parents=True)\n",
        "\n",
        "\n",
        "# Download pizza, steak and sushi data\n",
        "# open skapar en zip fil som sedan fylls genom request\n",
        "importLib.import_from_github('https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip',directory=data_path)\n",
        "with zipfile.ZipFile(data_path/'pizza_steak_sushi.zip', 'r') as zip_ref:\n",
        "    print('Unzipping pizza, steak and sushi data')\n",
        "    zip_ref.extractall(image_path)\n",
        "Path.unlink(data_path/'pizza_steak_sushi.zip')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8OFgwQF1CkOu"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "# Use ImageFolder to create dataset(s)\n",
        "\n",
        "train_path = image_path / 'train'\n",
        "test_path = image_path / 'test'\n",
        "\n",
        "to_dataset_transforms = transforms.Compose([\n",
        "    transforms.Resize((64,64)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_data =  ImageFolder(\n",
        "    root=train_path,\n",
        "    transform=to_dataset_transforms)\n",
        "\n",
        "test_data =  ImageFolder(\n",
        "    root=test_path,\n",
        "    transform=to_dataset_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbT0fhXHEQyJ",
        "outputId": "ad2b0da9-285c-493d-c362-a6b00e5d2197"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['pizza', 'steak', 'sushi']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get class names as a list\n",
        "class_names = train_data.classes\n",
        "class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCcWk7NDEay1",
        "outputId": "88718fd6-c6b2-4132-9383-0a64a0a7bcee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'pizza': 0, 'steak': 1, 'sushi': 2}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Can also get class names as a dict\n",
        "class_dict = train_data.class_to_idx\n",
        "class_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7H7bX4HEgie",
        "outputId": "2ff1fdd2-f990-461d-c2e9-27435e7744c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(225, 75)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the lengths of each dataset\n",
        "len(train_data), len(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nskNr5YCEoRl",
        "outputId": "cd825b1d-095f-4080-86ce-7d17aafef7e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x128bba290>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x128bb2790>)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Turn train and test Datasets into DataLoaders\n",
        "from os import cpu_count\n",
        "from torch.utils.data import DataLoader\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = round(cpu_count()*(3/4))\n",
        "train_dataloader = DataLoader(\n",
        "    dataset=train_data,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=NUM_WORKERS)\n",
        "test_dataloader = DataLoader(\n",
        "    dataset=test_data,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS)\n",
        "train_dataloader, test_dataloader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8vJxmxAFqw6",
        "outputId": "e5a8bd88-1b05-4109-de5a-8183a85c7872"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8, 3)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# How many batches of images are in our data loaders?\n",
        "len(train_dataloader), len(test_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeYFEqw8xK26"
      },
      "source": [
        "## 3. Recreate `model_0` we built in section 7 of notebook 04."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBErjcUCyDzE"
      },
      "outputs": [],
      "source": [
        "class TinyVGG(nn.Module):\n",
        "    def __init__(self, input_features:int,output_features:int, hidden_units:int=10):\n",
        "        super().__init__()\n",
        "        self.conv_block_1 = nn.Sequential(\n",
        "            nn.Conv2d(input_features, hidden_units,\n",
        "                      kernel_size=3, stride=1, padding=0),\n",
        "            nn.ReLU(),\n",
        "\n",
        "\n",
        "            nn.Conv2d(hidden_units, hidden_units,\n",
        "                      kernel_size=3, stride=1, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.conv_block_2 = nn.Sequential(\n",
        "            nn.Conv2d(hidden_units, hidden_units,\n",
        "                      kernel_size=3, stride=1, padding=0),\n",
        "            nn.ReLU(),\n",
        "\n",
        "\n",
        "            nn.Conv2d(hidden_units, hidden_units,\n",
        "                      kernel_size=3, stride=1, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(hidden_units*13*13, output_features)\n",
        "        )\n",
        "    def forward(self, X:pt.Tensor) -> pt.Tensor:\n",
        "        X_change = self.conv_block_1(X)\n",
        "        X_change = self.conv_block_2(X_change)\n",
        "        # print(X_change.shape)\n",
        "        X_change = self.classifier(X_change)\n",
        "        return X_change"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKdEEFEqxM-8"
      },
      "source": [
        "## 4. Create training and testing functions for `model_0`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "rnUox1qayDes"
      },
      "outputs": [],
      "source": [
        "def train_step(model: pt.nn.Module,\n",
        "               dataloader: pt.utils.data.DataLoader,\n",
        "               loss_fn: pt.nn.Module,\n",
        "               optimizer: pt.optim.Optimizer):\n",
        "  \n",
        "  # Put the model in train mode\n",
        "  model.train()\n",
        "\n",
        "  # Setup train loss and train accuracy values\n",
        "  train_loss, train_acc = 0, 0\n",
        "\n",
        "  # Loop through data loader and data batches\n",
        "  for i,(X,y) in dataloader:\n",
        "    # Send data to target device\n",
        "    X,y = X.to(device), y.to(device)\n",
        "    # 1. Forward pass\n",
        "    y_logits = model(X)\n",
        "    # 2. Calculate and accumulate loss\n",
        "    loss = loss_fn(y_logits, y)\n",
        "    train_loss += loss\n",
        "    train_acc = (pt.argmax(y_logits, dim=1)==y).sum().item()/len(X)\n",
        "\n",
        "    # 3. Optimizer zero grad \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backward \n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "  # Calculate and accumualte accuracy metric across all batches\n",
        "  \n",
        "\n",
        "  # Adjust metrics to get average loss and average accuracy per batch\n",
        "  train_acc /= len(dataloader)\n",
        "  train_loss /= len(dataloader)\n",
        "  return train_acc, train_loss\n",
        "  #! fortsetzen und gucken durch\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "O7_EVPpHNKUP"
      },
      "outputs": [],
      "source": [
        "def test_step(model: pt.nn.Module,\n",
        "              dataloader: pt.utils.data.DataLoader,\n",
        "              loss_fn: pt.nn.Module):\n",
        "  \n",
        "  # Put model in eval mode\n",
        "  model.eval()\n",
        "\n",
        "  # Setup the test loss and test accuracy values\n",
        "  test_loss, test_acc = 0, 0\n",
        "\n",
        "  # Turn on inference context manager\n",
        "  \n",
        "    # Loop through DataLoader batches\n",
        "    \n",
        "      # Send data to target device\n",
        "      \n",
        "\n",
        "      # 1. Forward pass\n",
        "      \n",
        "\n",
        "      # 2. Calculuate and accumulate loss\n",
        "\n",
        "\n",
        "      # Calculate and accumulate accuracy\n",
        "\n",
        "    \n",
        "  # Adjust metrics to get average loss and accuracy per batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "zXxTIh9tOh68"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "def train(model: pt.nn.Module,\n",
        "          train_dataloader: pt.utils.data.DataLoader,\n",
        "          test_dataloader: pt.utils.data.DataLoader,\n",
        "          optimizer: pt.optim.Optimizer,\n",
        "          loss_fn: pt.nn.Module = nn.CrossEntropyLoss(),\n",
        "          epochs: int = 5):\n",
        "  \n",
        "  # Create results dictionary\n",
        "  results = {\"train_loss\": [],\n",
        "             \"train_acc\": [],\n",
        "             \"test_loss\": [],\n",
        "             \"test_acc\": []}\n",
        "\n",
        "  # Loop through the training and testing steps for a number of epochs\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    # Train step\n",
        "    train_loss, train_acc = train_step(model=model, \n",
        "                                       dataloader=train_dataloader,\n",
        "                                       loss_fn=loss_fn,\n",
        "                                       optimizer=optimizer)\n",
        "    # Test step\n",
        "    test_loss, test_acc = test_step(model=model, \n",
        "                                    dataloader=test_dataloader,\n",
        "                                    loss_fn=loss_fn)\n",
        "    \n",
        "    # Print out what's happening\n",
        "    print(f\"Epoch: {epoch+1} | \"\n",
        "          f\"train_loss: {train_loss:.4f} | \"\n",
        "          f\"train_acc: {train_acc:.4f} | \"\n",
        "          f\"test_loss: {test_loss:.4f} | \"\n",
        "          f\"test_acc: {test_acc:.4f}\"\n",
        "    )\n",
        "\n",
        "    # Update the results dictionary\n",
        "    results[\"train_loss\"].append(train_loss)\n",
        "    results[\"train_acc\"].append(train_acc)\n",
        "    results[\"test_loss\"].append(test_loss)\n",
        "    results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "  # Return the results dictionary\n",
        "  return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvf-3pODxXYI"
      },
      "source": [
        "## 5. Try training the model you made in exercise 3 for 5, 20 and 50 epochs, what happens to the results?\n",
        "* Use `pt.optim.Adam()` with a learning rate of 0.001 as the optimizer. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "rV7s2qtIyDIZ"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Adam.__init__() missing 1 required positional argument: 'params'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[22], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m pt\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mmanual_seed(\u001b[39m42\u001b[39m)\n\u001b[1;32m      5\u001b[0m loss_fn \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m----> 6\u001b[0m optimizer \u001b[39m=\u001b[39m pt\u001b[39m.\u001b[39;49moptim\u001b[39m.\u001b[39;49mAdam(\u001b[39m#TODO, \u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m                              lr\u001b[39m=\u001b[39;49m\u001b[39m0.001\u001b[39;49m)\n",
            "\u001b[0;31mTypeError\u001b[0m: Adam.__init__() missing 1 required positional argument: 'params'"
          ]
        }
      ],
      "source": [
        "# Train for 5 epochs\n",
        "pt.manual_seed(42)\n",
        "pt.cuda.manual_seed(42)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = pt.optim.Adam(#TODO, \n",
        "                             lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEtZzyF1QGTq"
      },
      "outputs": [],
      "source": [
        "# Train for 20 epochs\n",
        "pt.manual_seed(42)\n",
        "pt.cuda.manual_seed(42)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = pt.optim.Adam(#TODO, \n",
        "                             lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dwvg40qAQGP9"
      },
      "outputs": [],
      "source": [
        "# Train for 50 epochs\n",
        "pt.manual_seed(42)\n",
        "pt.cuda.manual_seed(42)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = pt.optim.Adam(#TODO, \n",
        "                             lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fn8_fDGzQGMn"
      },
      "source": [
        "It looks like our model is starting to overfit towards the end (performing far better on the training data than on the testing data).\n",
        "\n",
        "In order to fix this, we'd have to introduce ways of preventing overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxZW-uAbxe_F"
      },
      "source": [
        "## 6. Double the number of hidden units in your model and train it for 20 epochs, what happens to the results?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdRM86voyC0x"
      },
      "outputs": [],
      "source": [
        "# Double the number of hidden units and train for 20 epochs\n",
        "pt.manual_seed(42)\n",
        "pt.cuda.manual_seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THYGHbxyTfzM"
      },
      "source": [
        "It looks like the model is still overfitting, even when changing the number of hidden units.\n",
        "\n",
        "To fix this, we'd have to look at ways to prevent overfitting with our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPDzW0wxhi3"
      },
      "source": [
        "## 7. Double the data you're using with your model from step 6 and train it for 20 epochs, what happens to the results?\n",
        "* **Note:** You can use the [custom data creation notebook](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/04_custom_data_creation.ipynb) to scale up your Food101 dataset.\n",
        "* You can also find the [already formatted double data (20% instead of 10% subset) dataset on GitHub](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/data/pizza_steak_sushi_20_percent.zip), you will need to write download code like in exercise 2 to get it into this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tWfa7Y0yCkX"
      },
      "outputs": [],
      "source": [
        "# Download 20% data for Pizza/Steak/Sushi from GitHub\n",
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup path to data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi_20_percent\"\n",
        "\n",
        "# If the image folder doesn't exist, download it and prepare it... \n",
        "if image_path.is_dir():\n",
        "    print(f\"{image_path} directory exists.\")\n",
        "else:\n",
        "    print(f\"Did not find {image_path} directory, creating one...\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "# Download pizza, steak, sushi data\n",
        "with open(data_path / \"pizza_steak_sushi_20_percent.zip\", \"wb\") as f:\n",
        "    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip\")\n",
        "    print(\"Downloading pizza, steak, sushi 20% data...\")\n",
        "    f.write(request.content)\n",
        "\n",
        "# Unzip pizza, steak, sushi data\n",
        "with zipfile.ZipFile(data_path / \"pizza_steak_sushi_20_percent.zip\", \"r\") as zip_ref:\n",
        "    print(\"Unzipping pizza, steak, sushi 20% data...\") \n",
        "    zip_ref.extractall(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrFK2ScnVg4q"
      },
      "outputs": [],
      "source": [
        "# See how many images we have\n",
        "walk_through_dir(image_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhlWd-z-Vk22"
      },
      "source": [
        "Excellent, we now have double the training and testing images... "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNzXRfO1Tt1Q"
      },
      "outputs": [],
      "source": [
        "# Create the train and test paths\n",
        "train_data_20_percent_path = image_path / \"train\"\n",
        "test_data_20_percent_path = image_path / \"test\"\n",
        "\n",
        "train_data_20_percent_path, test_data_20_percent_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1_xU3FQUPkN"
      },
      "outputs": [],
      "source": [
        "# Turn the 20 percent datapaths into Datasets and DataLoaders\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "simple_transform = transforms.Compose([\n",
        "  transforms.Resize((64, 64)),                                     \n",
        "  transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Create datasets\n",
        "\n",
        "\n",
        "# Create dataloaders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuJ9YpRCVXRm"
      },
      "outputs": [],
      "source": [
        "# Train a model with increased amount of data\n",
        "pt.manual_seed(42)\n",
        "pt.cuda.manual_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCCVfXk5xjYS"
      },
      "source": [
        "## 8. Make a prediction on your own custom image of pizza/steak/sushi (you could even download one from the internet) with your trained model from exercise 7 and share your prediction. \n",
        "* Does the model you trained in exercise 7 get it right? \n",
        "* If not, what do you think you could do to improve it?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1X-33t0vT20"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyO06uacGGDzw0TkyZ8mqgSU",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "04_pytorch_custom_datasets_exercises.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11.1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
