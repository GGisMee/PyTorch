{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program to rate characters\n",
    "Create a model based on a persons appeal to different characters in Genshin Impact\n",
    "Following this form: https://forms.office.com/Pages/ResponseDetailPage.aspx?id=tTAKZi6OaUe560ryi_0SvUHGZGPvcItElIw3gzwgl7NUMFJZUE5aNDVORVVMRENTSzFQV0laTjc4Vy4u&rid=4&GetResponseToken=q7rahzF2E7Igy2bHzBfrQBctplWW1STeVmCDaCKbsME&origin=rc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as pt\n",
    "from torch import nn\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "device = \"cuda\" if pt.cuda.is_available() else \"cpu\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 3. 5. 1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "from sys import path\n",
    "\n",
    "InputData = pd.read_csv(path[0]+'/db.csv').drop(columns='Name')\n",
    "InputData = InputData.to_numpy(dtype=np.double)\n",
    "\n",
    "TotalOutputData = pd.read_csv(path[0]+'/rating.csv').drop(columns='Name')\n",
    "\n",
    "Chosen_person = 'Gustav'\n",
    "OutputData = TotalOutputData[Chosen_person].to_numpy(dtype=np.double)\n",
    "\n",
    "print(InputData[0])\n",
    "print(OutputData[0])\n",
    "\n",
    "#del TotalOutputData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 4.9879518072289155\n",
      "Max: 9.0\n",
      "Min: 1.0\n",
      "Mode: [3 4]\n"
     ]
    }
   ],
   "source": [
    "# analyse the data\n",
    "print(f'Mean: {OutputData.mean()}')\n",
    "print(f'Max: {OutputData.max()}')\n",
    "print(f'Min: {OutputData.min()}')\n",
    "\n",
    "vals, counts = np.unique(OutputData, return_counts=True)\n",
    "mode_value = np.argwhere(counts == np.max(counts))\n",
    "print(f'Mode: {mode_value.flatten()}') # if there are two values there are equally many of both\n",
    "del vals, counts, mode_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 2. 7. 1. 1. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [0. 3. 5. 1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 2. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 3. 5. 1. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 2. 6. 1. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      " [0. 2. 4. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 2. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 2. 4. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 2. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 2. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 2. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 2. 3. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 3. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 3. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 3. 6. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 3. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 3. 8. 1. 1. 0. 0. 0. 0. 0. 0. 1.]] \n",
      "\n",
      " [3. 4. 5. 4. 4. 5. 8. 6. 9. 7. 6. 6. 5. 4. 5. 4. 5.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "input_train, input_test, output_train, output_test = train_test_split(InputData, OutputData, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(input_test, \"\\n\"*2, output_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a model + loss fn, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "pt.manual_seed(42)\n",
    "\n",
    "class ModelV0(nn.Module):\n",
    "    def __init__(self, input_features:int = 12, output_features:int = 1, hidden_units:int = 10):\n",
    "        super().__init__()\n",
    "        self.Layer_1 = nn.Linear(in_features=input_features, out_features=hidden_units)\n",
    "        self.Layer_2 = nn.Linear(in_features=hidden_units, out_features=hidden_units)\n",
    "        self.Layer_3 = nn.Linear(in_features=hidden_units, out_features=output_features)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        return self.Layer_3(self.Layer_2(self.relu(self.Layer_1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = ModelV0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss() # BCEWithLogitsLoss has tha sigmoid activation function built in\n",
    " \n",
    "optimizer = pt.optim.SGD(params=model0.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy, how meny of the the examples the model gets right\n",
    "def accuracy_fn(y_preds, y_true):\n",
    "    \"\"\"tar antalet där y_true == y_preds\n",
    "    \n",
    "    Tar detta värdet delat med det hela alltså y_pred * 100 för att få % enheten av gissningar som är rätt\"\"\"\n",
    "    correct = pt.eq(y_true, y_preds).sum().item() # sum tar summan av alla true som även kan ses som 1. item gör sedan om denna summerade siffra från tensor till nummer\n",
    "    acc = (correct/len(y_preds)) * 100 # delen delat med det hela\n",
    "    return acc\n",
    "\n",
    "def standard_devision_func(y_preds, y_true):\n",
    "    diff = y_preds-y_true\n",
    "    return pt.std(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 2. 3. 1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 2. 5. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 2. 5. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 3. 4. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 7. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 2. 7. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [1. 3. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 3. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 2. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 2. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 2. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
      " [1. 2. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 2. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1.]\n",
      " [0. 2. 7. 1. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 2. 4. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 2. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 2. 1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 2. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      " [0. 2. 2. 1. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 3. 5. 1. 0. 0. 0. 1. 0. 1. 0. 0.]\n",
      " [0. 2. 5. 1. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 3. 7. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 7. 1. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 3. 3. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 2. 5. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 2. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 3. 5. 1. 1. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 3. 4. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 2. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 3. 7. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 2. 6. 0. 0. 1. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 2. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [1. 3. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      " [0. 3. 5. 1. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [0. 3. 4. 1. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 2. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 2. 3. 1. 0. 1. 0. 0. 0. 1. 0. 1.]\n",
      " [0. 2. 3. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 2. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 2. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [0. 3. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [0. 2. 4. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 3. 7. 1. 0. 0. 0. 0. 1. 1. 0. 1.]\n",
      " [1. 3. 2. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 2. 6. 1. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      " [0. 1. 3. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      " [0. 3. 8. 1. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      " [0. 2. 4. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 2. 4. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 2. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 3. 2. 0. 1. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 2. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 3. 5. 1. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#print((input_train.shape))\n",
    "print(input_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([66, 12])\n",
      "torch.Size([17, 12])\n",
      "train loss: 29.821107864379883, train acc: 0.0,  test loss: 30.352941176470587, test acc: 0.0, test std: 1.5718104959867516\n",
      "train loss: 7.309077262878418, train acc: 10.606060606060606,  test loss: 7.764705882352941, test acc: 5.88235294117647, test std: 2.7034835914818798\n",
      "train loss: 4.828013896942139, train acc: 15.151515151515152,  test loss: 4.9411764705882355, test acc: 17.647058823529413, test std: 2.2096047024697585\n",
      "train loss: 3.556018829345703, train acc: 24.242424242424242,  test loss: 4.470588235294118, test acc: 17.647058823529413, test std: 2.093407017561676\n",
      "train loss: 3.0418124198913574, train acc: 21.21212121212121,  test loss: 2.823529411764706, test acc: 23.52941176470588, test std: 1.6627404735414788\n",
      "train loss: 2.8448452949523926, train acc: 27.27272727272727,  test loss: 2.764705882352941, test acc: 29.411764705882355, test std: 1.6247171699569565\n",
      "train loss: 2.7160146236419678, train acc: 27.27272727272727,  test loss: 2.6470588235294117, test acc: 23.52941176470588, test std: 1.6224527546823884\n",
      "train loss: 2.607574224472046, train acc: 28.78787878787879,  test loss: 2.7058823529411766, test acc: 17.647058823529413, test std: 1.6247171699569565\n",
      "train loss: 2.5120623111724854, train acc: 28.78787878787879,  test loss: 2.235294117647059, test acc: 17.647058823529413, test std: 1.4975470138942315\n",
      "train loss: 2.4265923500061035, train acc: 28.78787878787879,  test loss: 2.235294117647059, test acc: 17.647058823529413, test std: 1.4975470138942315\n"
     ]
    }
   ],
   "source": [
    "pt.manual_seed(42)\n",
    "pt.cuda.manual_seed(42)\n",
    "try:\n",
    "    input_train, output_train = pt.from_numpy(input_train).to(device), pt.from_numpy(output_train).to(device)\n",
    "    input_test, output_test = pt.from_numpy(input_test).to(device), pt.from_numpy(output_test).to(device)\n",
    "except TypeError:\n",
    "    print('Already tensor')\n",
    "\n",
    "print(input_train.shape)\n",
    "# print(input_train.dtype)\n",
    "# print(output_test.dtype)\n",
    "print(input_test.shape)\n",
    "\n",
    "# exit()\n",
    "for epoch in range(100):\n",
    "\n",
    "    model0.train()\n",
    "\n",
    "    y_logits = model0(input_train.to(pt.float32)).squeeze()\n",
    "    # print(y_logits)\n",
    "    y_preds = pt.round((y_logits))\n",
    "    #print(y_logits.dtype, output_train.dtype)\n",
    "    loss = loss_fn(y_logits, output_train.to(pt.float32))\n",
    "    train_acc = accuracy_fn(y_preds, output_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward() # backwards propogation\n",
    "\n",
    "    optimizer.step() # gradient descend\n",
    "\n",
    "    model0.eval()\n",
    "    with pt.inference_mode():\n",
    "        test_logits = model0(input_test.to(pt.float32)).squeeze()\n",
    "        test_preds = pt.round((test_logits))\n",
    "        test_loss = loss_fn(test_preds, output_test)\n",
    "        test_acc = accuracy_fn(test_preds, output_test)\n",
    "        test_std = standard_devision_func(test_preds, output_test)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"train loss: {loss}, train acc: {train_acc},  test loss: {test_loss}, test acc: {test_acc}, test std: {test_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.8695])\n",
      "tensor(5., dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with pt.inference_mode():\n",
    "    num = 14\n",
    "    sample = input_test[num]\n",
    "    logits = model0(sample.to(pt.float32))\n",
    "    print((logits))\n",
    "    print(output_test[num])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
