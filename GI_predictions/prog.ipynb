{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program to rate characters\n",
    "Create a model based on a persons appeal to different characters in Genshin Impact\n",
    "Following this form: https://forms.office.com/Pages/ResponseDetailPage.aspx?id=tTAKZi6OaUe560ryi_0SvUHGZGPvcItElIw3gzwgl7NUMFJZUE5aNDVORVVMRENTSzFQV0laTjc4Vy4u&rid=4&GetResponseToken=q7rahzF2E7Igy2bHzBfrQBctplWW1STeVmCDaCKbsME&origin=rc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as pt\n",
    "from torch import nn\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "device = \"cuda\" if pt.cuda.is_available() else \"cpu\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 3. 5. 1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "7.0\n"
     ]
    }
   ],
   "source": [
    "from sys import path\n",
    "\n",
    "InputData = pd.read_csv(path[0]+'/db.csv').drop(columns='Name')\n",
    "InputData = InputData.to_numpy(dtype=np.double)\n",
    "\n",
    "TotalOutputData = pd.read_csv(path[0]+'/fulldata.csv').drop(columns='Name')\n",
    "\n",
    "Chosen_person = 'A'\n",
    "OutputData = TotalOutputData[Chosen_person].to_numpy(dtype=np.double)\n",
    "\n",
    "print(InputData[0])\n",
    "print(OutputData[0])\n",
    "\n",
    "#del TotalOutputData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 5.903614457831325\n",
      "Max: 10.0\n",
      "Min: 1.0\n",
      "Mode: [7]\n"
     ]
    }
   ],
   "source": [
    "# analyse the data\n",
    "print(f'Mean: {OutputData.mean()}')\n",
    "print(f'Max: {OutputData.max()}')\n",
    "print(f'Min: {OutputData.min()}')\n",
    "\n",
    "vals, counts = np.unique(OutputData, return_counts=True)\n",
    "mode_value = np.argwhere(counts == np.max(counts))\n",
    "print(f'Mode: {mode_value.flatten()}') # if there are two values there are equally many of both\n",
    "del vals, counts, mode_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 2. 7. 1. 1. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [0. 3. 5. 1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 2. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 3. 5. 1. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 2. 6. 1. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      " [0. 2. 4. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 2. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 2. 4. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 2. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 2. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 2. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 2. 3. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 3. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 3. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 3. 6. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 3. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 3. 8. 1. 1. 0. 0. 0. 0. 0. 0. 1.]] \n",
      "\n",
      " [2. 7. 6. 8. 6. 8. 6. 5. 8. 3. 3. 7. 8. 8. 8. 3. 8.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "input_train, input_test, output_train, output_test = train_test_split(InputData, OutputData, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(input_test, \"\\n\"*2, output_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a model + loss fn, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "pt.manual_seed(42)\n",
    "\n",
    "class ModelV0(nn.Module):\n",
    "    def __init__(self, input_features:int = 12, output_features:int = 1, hidden_units:int = 20):\n",
    "        super().__init__()\n",
    "        self.Layer_1 = nn.Linear(in_features=input_features, out_features=hidden_units)\n",
    "        #self.Layer_2 = nn.Linear(in_features=hidden_units, out_features=hidden_units)\n",
    "        self.Layer_3 = nn.Linear(in_features=hidden_units, out_features=output_features)\n",
    "        #self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        return self.Layer_3(((self.Layer_1(x)))) # self.Layer_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = ModelV0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss() # BCEWithLogitsLoss has tha sigmoid activation function built in\n",
    " \n",
    "optimizer = pt.optim.SGD(params=model0.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy, how meny of the the examples the model gets right\n",
    "def accuracy_fn(y_preds, y_true):\n",
    "    \"\"\"tar antalet där y_true == y_preds\n",
    "    \n",
    "    Tar detta värdet delat med det hela alltså y_pred * 100 för att få % enheten av gissningar som är rätt\"\"\"\n",
    "    correct = pt.eq(y_true, y_preds).sum().item() # sum tar summan av alla true som även kan ses som 1. item gör sedan om denna summerade siffra från tensor till nummer\n",
    "    acc = (correct/len(y_preds)) * 100 # delen delat med det hela\n",
    "    return acc\n",
    "\n",
    "def standard_devision_func(y_preds, y_true):\n",
    "    diff = y_preds-y_true\n",
    "    return pt.std(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 2. 3. 1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 2. 5. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 2. 5. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 3. 4. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 7. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 2. 7. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [1. 3. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 3. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 2. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 2. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 2. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
      " [1. 2. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 2. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1.]\n",
      " [0. 2. 7. 1. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 2. 4. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 2. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 2. 1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 2. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      " [0. 2. 2. 1. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 3. 5. 1. 0. 0. 0. 1. 0. 1. 0. 0.]\n",
      " [0. 2. 5. 1. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 3. 7. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 7. 1. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 3. 3. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 2. 5. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 2. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 3. 5. 1. 1. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 3. 4. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 2. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 3. 7. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 2. 6. 0. 0. 1. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 2. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [1. 3. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      " [0. 3. 5. 1. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [0. 3. 4. 1. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 2. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 2. 3. 1. 0. 1. 0. 0. 0. 1. 0. 1.]\n",
      " [0. 2. 3. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 2. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 2. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [0. 3. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [0. 2. 4. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 3. 7. 1. 0. 0. 0. 0. 1. 1. 0. 1.]\n",
      " [1. 3. 2. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 2. 6. 1. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      " [0. 1. 3. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      " [0. 3. 8. 1. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      " [0. 2. 4. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 2. 4. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 2. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 3. 2. 0. 1. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 2. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 3. 5. 1. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#print((input_train.shape))\n",
    "print(input_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([66, 12])\n",
      "torch.Size([17, 12])\n",
      "train loss: 42.20077133178711, train acc: 0.0,  test loss: 18.352941176470587, test acc: 0.0, test std: 2.3168183050950564\n",
      "train loss: 3.7211501598358154, train acc: 18.181818181818183,  test loss: 4.9411764705882355, test acc: 17.647058823529413, test std: 2.2880765104443204\n",
      "train loss: 3.547430992126465, train acc: 22.727272727272727,  test loss: 4.470588235294118, test acc: 17.647058823529413, test std: 2.176073095658107\n",
      "train loss: 3.4941065311431885, train acc: 25.757575757575758,  test loss: 5.0588235294117645, test acc: 17.647058823529413, test std: 2.315230899423869\n",
      "train loss: 3.47273588180542, train acc: 28.78787878787879,  test loss: 5.0588235294117645, test acc: 17.647058823529413, test std: 2.315230899423869\n",
      "train loss: 3.4625132083892822, train acc: 27.27272727272727,  test loss: 4.529411764705882, test acc: 17.647058823529413, test std: 2.1861865804880156\n"
     ]
    }
   ],
   "source": [
    "pt.manual_seed(42)\n",
    "pt.cuda.manual_seed(42)\n",
    "try:\n",
    "    input_train, output_train = pt.from_numpy(input_train).to(device), pt.from_numpy(output_train).to(device)\n",
    "    input_test, output_test = pt.from_numpy(input_test).to(device), pt.from_numpy(output_test).to(device)\n",
    "except TypeError:\n",
    "    print('Already tensor')\n",
    "\n",
    "print(input_train.shape)\n",
    "# print(input_train.dtype)\n",
    "# print(output_test.dtype)\n",
    "print(input_test.shape)\n",
    "\n",
    "# exit()\n",
    "for epoch in range(600):\n",
    "\n",
    "    model0.train()\n",
    "\n",
    "    y_logits = model0(input_train.to(pt.float32)).squeeze()\n",
    "    # print(y_logits)\n",
    "    y_preds = pt.round((y_logits))\n",
    "    #print(y_logits.dtype, output_train.dtype)\n",
    "    loss = loss_fn(y_logits, output_train.to(pt.float32))\n",
    "    train_acc = accuracy_fn(y_preds, output_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward() # backwards propogation\n",
    "\n",
    "    optimizer.step() # gradient descend\n",
    "\n",
    "    model0.eval()\n",
    "    with pt.inference_mode():\n",
    "        test_logits = model0(input_test.to(pt.float32)).squeeze()\n",
    "        test_preds = pt.round((test_logits))\n",
    "        test_loss = loss_fn(test_preds, output_test)\n",
    "        test_acc = accuracy_fn(test_preds, output_test)\n",
    "        test_std = standard_devision_func(test_preds, output_test)\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"train loss: {loss}, train acc: {train_acc},  test loss: {test_loss}, test acc: {test_acc}, test std: {test_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.8473])\n",
      "tensor(3., dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with pt.inference_mode():\n",
    "    num = 10\n",
    "    sample = input_test[num]\n",
    "    logits = model0(sample.to(pt.float32))\n",
    "    print((logits))\n",
    "    print(output_test[num])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
