{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program to rate characters\n",
    "Create a model based on a persons appeal to different characters in Genshin Impact\n",
    "Following this form: https://forms.office.com/Pages/ResponseDetailPage.aspx?id=tTAKZi6OaUe560ryi_0SvUHGZGPvcItElIw3gzwgl7NUMFJZUE5aNDVORVVMRENTSzFQV0laTjc4Vy4u&rid=4&GetResponseToken=q7rahzF2E7Igy2bHzBfrQBctplWW1STeVmCDaCKbsME&origin=rc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as pt\n",
    "from torch import nn\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "device = \"cuda\" if pt.cuda.is_available() else \"cpu\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 3. 5. 1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "from sys import path\n",
    "\n",
    "InputData = pd.read_csv(path[0]+'/db.csv').drop(columns='Name')\n",
    "InputData = InputData.to_numpy(dtype=np.double)\n",
    "\n",
    "TotalOutputData = pd.read_csv(path[0]+'/rating.csv').drop(columns='Name')\n",
    "\n",
    "Chosen_person = 'Gustav'\n",
    "OutputData = TotalOutputData[Chosen_person].to_numpy(dtype=np.double)\n",
    "\n",
    "print(InputData[0])\n",
    "print(OutputData[0])\n",
    "\n",
    "#del TotalOutputData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 4.9879518072289155\n",
      "Max: 9.0\n",
      "Min: 1.0\n",
      "Mode: [3 4]\n"
     ]
    }
   ],
   "source": [
    "# analyse the data\n",
    "print(f'Mean: {OutputData.mean()}')\n",
    "print(f'Max: {OutputData.max()}')\n",
    "print(f'Min: {OutputData.min()}')\n",
    "\n",
    "vals, counts = np.unique(OutputData, return_counts=True)\n",
    "mode_value = np.argwhere(counts == np.max(counts))\n",
    "print(f'Mode: {mode_value.flatten()}') # if there are two values there are equally many of both\n",
    "del vals, counts, mode_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 2. 7. 1. 1. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [0. 3. 5. 1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 2. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 3. 5. 1. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 2. 6. 1. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      " [0. 2. 4. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 2. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 2. 4. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 2. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 2. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 2. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 2. 3. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 3. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 3. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 3. 6. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 3. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 3. 8. 1. 1. 0. 0. 0. 0. 0. 0. 1.]] \n",
      "\n",
      " [3. 4. 5. 4. 4. 5. 8. 6. 9. 7. 6. 6. 5. 4. 5. 4. 5.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "input_train, input_test, output_train, output_test = train_test_split(InputData, OutputData, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(input_test, \"\\n\"*2, output_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a model + loss fn, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "pt.manual_seed(42)\n",
    "\n",
    "class ModelV0(nn.Module):\n",
    "    def __init__(self, input_features:int = 12, output_features:int = 66, hidden_units:int = 10):\n",
    "        super().__init__()\n",
    "        self.Layer_1 = nn.Linear(in_features=input_features, out_features=hidden_units)\n",
    "        self.layer_2 = nn.Linear(in_features=hidden_units, out_features=output_features)\n",
    "    def forward(self, x):\n",
    "        x = self.Layer_1(x)\n",
    "        return self.layer_2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = ModelV0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss() # BCEWithLogitsLoss has tha sigmoid activation function built in\n",
    " \n",
    "optimizer = pt.optim.SGD(params=model0.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy, how meny of the the examples the model gets right\n",
    "def accuracy_fn(y_preds, y_true):\n",
    "    \"\"\"tar antalet där y_true == y_preds\n",
    "    \n",
    "    Tar detta värdet delat med det hela alltså y_pred * 100 för att få % enheten av gissningar som är rätt\"\"\"\n",
    "    correct = pt.eq(y_true, y_preds).sum().item() # sum tar summan av alla true som även kan ses som 1. item gör sedan om denna summerade siffra från tensor till nummer\n",
    "    acc = (correct/len(y_preds)) * 100 # delen delat med det hela\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 2. 3. 1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 2. 5. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 2. 5. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 3. 4. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 7. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 2. 7. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [1. 3. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 3. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 2. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 2. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 2. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
      " [1. 2. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 2. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1.]\n",
      " [0. 2. 7. 1. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 2. 4. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 2. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 2. 1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 2. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      " [0. 2. 2. 1. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 3. 5. 1. 0. 0. 0. 1. 0. 1. 0. 0.]\n",
      " [0. 2. 5. 1. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 3. 7. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 7. 1. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 3. 3. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 2. 5. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 2. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 3. 5. 1. 1. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 3. 4. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 2. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 3. 7. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 2. 6. 0. 0. 1. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 2. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [1. 3. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      " [0. 3. 5. 1. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [0. 3. 4. 1. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 2. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 2. 3. 1. 0. 1. 0. 0. 0. 1. 0. 1.]\n",
      " [0. 2. 3. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 2. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 2. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [0. 3. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [0. 2. 4. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 3. 7. 1. 0. 0. 0. 0. 1. 1. 0. 1.]\n",
      " [1. 3. 2. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 2. 6. 1. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      " [0. 1. 3. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      " [0. 3. 8. 1. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      " [0. 2. 4. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 2. 4. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 2. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 3. 2. 0. 1. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 2. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 3. 5. 1. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#print((input_train.shape))\n",
    "print(input_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already tensor\n",
      "torch.Size([66])\n",
      "tensor([[ 0.7014, -0.0072, -0.1464,  ..., -0.0570,  0.2511,  0.0942],\n",
      "        [ 0.7622, -0.5211, -0.5952,  ...,  0.4758,  0.5056,  0.4253],\n",
      "        [ 0.8315, -0.6317, -1.0339,  ...,  0.5162,  0.5739,  0.3580],\n",
      "        ...,\n",
      "        [ 0.8863, -0.4440, -0.4377,  ...,  0.4220,  0.3435,  0.3187],\n",
      "        [ 1.1436, -0.8814, -0.9149,  ...,  0.4960,  0.8274,  0.4624],\n",
      "        [ 0.6128, -0.1211, -0.2502,  ...,  0.2223,  0.2097,  0.3404]],\n",
      "       grad_fn=<SqueezeBackward0>)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([66])) must be the same as input size (torch.Size([66, 66]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_logits)\n\u001b[1;32m     17\u001b[0m y_preds \u001b[38;5;241m=\u001b[39m pt\u001b[38;5;241m.\u001b[39mround(pt\u001b[38;5;241m.\u001b[39msigmoid(y_logits))\n\u001b[0;32m---> 18\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m train_acc \u001b[38;5;241m=\u001b[39m accuracy_fn(y_preds, output_train)\n\u001b[1;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/loss.py:720\u001b[0m, in \u001b[0;36mBCEWithLogitsLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 720\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m                                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/functional.py:3163\u001b[0m, in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   3160\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()):\n\u001b[0;32m-> 3163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) must be the same as input size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target\u001b[38;5;241m.\u001b[39msize(), \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m   3165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbinary_cross_entropy_with_logits(\u001b[38;5;28minput\u001b[39m, target, weight, pos_weight, reduction_enum)\n",
      "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([66])) must be the same as input size (torch.Size([66, 66]))"
     ]
    }
   ],
   "source": [
    "pt.manual_seed(42)\n",
    "pt.cuda.manual_seed(42)\n",
    "try:\n",
    "    input_train, output_train = pt.from_numpy(input_train).to(device), pt.from_numpy(output_train).to(device)\n",
    "    input_test, output_test = pt.from_numpy(input_test).to(device), pt.from_numpy(output_test).to(device)\n",
    "except TypeError:\n",
    "    print('Already tensor')\n",
    "\n",
    "print(output_train.shape)\n",
    "# exit()\n",
    "for epoch in range(100):\n",
    "\n",
    "    model0.train()\n",
    "\n",
    "    y_logits = model0(input_train.to(pt.float32)).squeeze()\n",
    "    print(y_logits)\n",
    "    y_preds = pt.round(pt.sigmoid(y_logits))\n",
    "    loss = loss_fn(y_logits, output_train)\n",
    "    train_acc = accuracy_fn(y_preds, output_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward() # backwards propogation\n",
    "\n",
    "    optimizer.step() # gradient descend\n",
    "\n",
    "    model0.eval()\n",
    "    with pt.inference_mode():\n",
    "        test_logits = model0(input_test).squeeze()\n",
    "        test_preds = pt.round(pt.sigmoid(test_logits))\n",
    "        test_loss = loss_fn(test_preds, output_test)\n",
    "        test_acc = accuracy_fn(test_preds, output_test)\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"train loss: {loss}, train acc: {train_acc},  test loss: {test_loss}, test acc: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
