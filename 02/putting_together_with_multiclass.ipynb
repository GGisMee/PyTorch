{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-8 Putting it all together with a multi class classification problem\n",
    "* Binary classification have 2 options\n",
    "* Multiclass classification have more then 2 options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as pt\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "import helper_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the data, then to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the hyperparamaters\n",
    "NUM_CLASSES = 4\n",
    "NUM_FEATURES = 2\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Create data\n",
    "X_blob, y_blob = make_blobs(n_samples=1000, \n",
    "                            n_features=NUM_FEATURES,\n",
    "                            centers=NUM_CLASSES,\n",
    "                            cluster_std=1.5,\n",
    "                            random_state=RANDOM_SEED)\n",
    "\n",
    "# To tensors\n",
    "X_blob = pt.from_numpy(X_blob).type(pt.float)\n",
    "y_blob = pt.from_numpy(y_blob).type(pt.float)\n",
    "\n",
    "# Split to train and test\n",
    "X_blob_train, X_blob_test, y_blob_train, y_blob_test = train_test_split(X_blob, y_blob, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_blob, type(y_blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(X_blob[:,0], X_blob[:,1], c=y_blob, cmap=plt.cm.RdYlBu)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if pt.cuda.is_available() else \"cpu\"\n",
    "pt.manual_seed(42)\n",
    "class BlobModel(nn.Module):\n",
    "    def __init__(self, input_features, output_features, hidden_units=8):\n",
    "        super().__init__()\n",
    "        self.linear_layer_stack = nn.Sequential(\n",
    "            nn.Linear(in_features=input_features, out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_features)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.linear_layer_stack(x)\n",
    "# Create an instance of the model\n",
    "model_4 = BlobModel(input_features=2, output_features=4).to(device)\n",
    "print(model_4) # 2 pg av 2 dimensioner av blobbar, 4 för 4 st klasser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Create an optimizer\n",
    "optimizer = pt.optim.SGD(params=model_4.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting prediction probs to multi-class pytorch model \n",
    "När man använder multiclass classification ska man använda softmax istället för sigmoid, eftersom den konverterar till en där alla blir 1 och tar tanke på alla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting prediction probabilities for a multi class PyTorch model\n",
    "# Raw outputs\n",
    "model_4.eval()\n",
    "with pt.inference_mode():\n",
    "    y_test_logits = model_4(X_blob_test.to(device))\n",
    "    print(y_test_logits)\n",
    "    y_pred_probs = pt.softmax(y_test_logits, dim=1)\n",
    "    print(y_pred_probs[:10])\n",
    "    print(pt.sum(y_pred_probs[0])) # sum av vald row blir 1\n",
    "\n",
    "    print(pt.argmax(y_pred_probs[0]).item()) # för att finna den klassen som är mest sannolik att det är"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our model's prediction probabilities to prediction labels\n",
    "y_preds = pt.argmax(y_pred_probs, dim=1)\n",
    "print(y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_blob_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_blob_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a training and testing loop for a multi-class pytorch model\n",
    "from ml_funcs import progress_viewer \n",
    "\n",
    "pv = progress_viewer()\n",
    "\n",
    "pt.manual_seed(42)\n",
    "pt.cuda.manual_seed(42)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "X_blob_train, y_blob_train = X_blob_train.to(device), y_blob_train.to(device)\n",
    "X_blob_test, y_blob_test = X_blob_test.to(device), y_blob_test.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_4.train()\n",
    "\n",
    "    train_logits = model_4(X_blob_train)\n",
    "    train_pred_probs = pt.softmax(train_logits, dim=1)\n",
    "    train_pred = train_pred_probs.argmax(dim=1)\n",
    "\n",
    "    loss = loss_fn(train_logits, y_blob_train.type(pt.LongTensor))\n",
    "    acc = helper_functions.accuracy_fn(y_blob_train, train_pred)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    model_4.eval()\n",
    "    with pt.inference_mode():\n",
    "        test_logits = model_4(X_blob_test)\n",
    "        test_pred = pt.softmax(test_logits, dim=1).argmax(dim=1)\n",
    "\n",
    "        test_loss = loss_fn(test_logits, y_blob_test.type(pt.LongTensor))\n",
    "        test_acc = helper_functions.accuracy_fn(y_blob_test, test_pred)\n",
    "    pv.add(loss.item(),acc,test_loss.item(), test_acc)\n",
    "pv.show()\n",
    "print(pv.df)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_results(X_train, y_train, X_test, y_test, model):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title(\"Train\")\n",
    "    helper_functions.plot_decision_boundary(model, X_train, y_train)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title(\"Test\")\n",
    "    helper_functions.plot_decision_boundary(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_results(X_blob_train, y_blob_train, X_blob_test, y_blob_test, model_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "from ml_funcs import save_model\n",
    "save_model(model_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#! load, testa sen\n",
    "\n",
    "from ml_funcs import load_model\n",
    "loaded_model = load_model(BlobModel,args_arr=[2,4])\n",
    "print(loaded_model.state_dict())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalutate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "model_4.eval()\n",
    "with pt.inference_mode():\n",
    "    y_logits = model_4(X_blob_test)\n",
    "    y_preds = pt.argmax(pt.softmax(y_logits, dim=1), dim=1)\n",
    "    print(y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few more classification metrics\n",
    "* Accuracy - how meny precent went right, bad for unbalenced scenarios\n",
    "* Precision # for unbalanced\n",
    "* Recall # for unbalanced\n",
    "* F1-score # combination of 2 above\n",
    "* Confusion matrix\n",
    "* Classification report\n",
    "\n",
    "extra: https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c\n",
    "\n",
    "A lot of PyTorch metrics att TorchMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "\n",
    "# Setup metric\n",
    "tm_accuracy = Accuracy('multiclass', num_classes=4).to(device)\n",
    "tm_accuracy(y_preds, y_blob_test).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises: \n",
    "https://www.learnpytorch.io/02_pytorch_classification/#exercises"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
