{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 The missing piece: non-linearity\n",
    "What patterns could you draw if you had a high amount of staight and non-straight lines? or linear and non linear functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_circles\n",
    "import ml_progress_viewer as ml_pv\n",
    "\n",
    "n_samples = 1000\n",
    "\n",
    "X,y = make_circles(n_samples, noise=0.03, random_state=42)\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1], c=y, cmap=plt.cm.RdYlBu)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tensors and then train and test data\n",
    "import torch as pt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = pt.from_numpy(X).type(pt.float)\n",
    "y = pt.from_numpy(y).type(pt.float)\n",
    "\n",
    "# Split int otrain and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train[:5], y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if pt.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Building a model with non-linearity (curved lines)\n",
    "info on chosen for this example: https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class CircleModelV2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(in_features=2, out_features=10)\n",
    "        self.layer_2 = nn.Linear(in_features=10, out_features=10)\n",
    "        self.layer_3 = nn.Linear(in_features=10, out_features=1)\n",
    "        self.relu = nn.ReLU() # ReLu is a non linear activation function\n",
    "    def forward(self, X):\n",
    "        return self.layer_3(self.layer_2(self.relu(self.layer_1(X))))\n",
    "model_3 = CircleModelV2().to(device)\n",
    "print(model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup loss and optimizer\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = pt.optim.SGD(params=model_3.parameters(), lr=0.1)\n",
    "\n",
    "\n",
    "# Calculate accuracy, how meny of the the examples the model gets right\n",
    "def accuracy_fn(y_preds, y_true):\n",
    "    \"\"\"tar antalet där y_true == y_preds\n",
    "    \n",
    "    Tar detta värdet delat med det hela alltså y_pred * 100 för att få % enheten av gissningar som är rätt\"\"\"\n",
    "    correct = pt.eq(y_true, y_preds).sum().item() # sum tar summan av alla true som även kan ses som 1. item gör sedan om denna summerade siffra från tensor till nummer\n",
    "    acc = (correct/len(y_preds)) * 100 # delen delat med det hela\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "\n",
    "# Random seeds \n",
    "pt.manual_seed(42)\n",
    "pt.cuda.manual_seed(42)\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "\n",
    "X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_3.train()\n",
    "\n",
    "    y_logits = model_3(X_train).squeeze()\n",
    "    y_preds = pt.round(pt.sigmoid(y_logits))\n",
    "    loss = loss_fn(y_logits, y_train)\n",
    "    train_acc = accuracy_fn(y_preds, y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward() # backwards propogation\n",
    "\n",
    "    optimizer.step() # gradient descend\n",
    "\n",
    "    model_3.eval()\n",
    "    with pt.inference_mode():\n",
    "        test_logits = model_3(X_test).squeeze()\n",
    "        test_preds = pt.round(pt.sigmoid(test_logits))\n",
    "        test_loss = loss_fn(test_preds, y_test)\n",
    "        test_acc = accuracy_fn(test_preds, y_test)\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"train loss: {loss}, train acc: {train_acc},  test loss: {test_loss}, test acc: {test_acc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import plot_decision_boundary\n",
    "def view_results(X_train, y_train, X_test, y_test, model):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title(\"Train\")\n",
    "    plot_decision_boundary(model, X_train, y_train)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title(\"Test\")\n",
    "    plot_decision_boundary(model, X_test, y_test)\n",
    "view_results(X_train, y_train, X_test, y_test, model_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
